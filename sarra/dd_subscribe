#!/usr/bin/python3
#
# This file is part of sarracenia.
# The sarracenia suite is Free and is proudly provided by the Government of Canada
# Copyright (C) Her Majesty The Queen in Right of Canada, Environment Canada, 2008-2015
#
# Questions or bugs report: dps-client@ec.gc.ca
# sarracenia repository: git://git.code.sf.net/p/metpx/git
# Documentation: http://metpx.sourceforge.net/#SarraDocumentation
#
# dd_subscribe    : python3 program allowing users to download product from dd.weather.gc.ca
#                   as soon as they are made available (through amqp notifications)
#
#
# Code contributed by:
#  Michel Grenier - Shared Services Canada
#  Jun Hu         - Shared Services Canada
#  Last Changed   : Sep 22 10:41:32 EDT 2015
#  Last Revision  : Sep 22 10:41:32 EDT 2015
#
########################################################################
#  This program is free software; you can redistribute it and/or modify
#  it under the terms of the GNU General Public License as published by
#  the Free Software Foundation; either version 2 of the License, or
#  (at your option) any later version.
#
#  This program is distributed in the hope that it will be useful, 
#  but WITHOUT ANY WARRANTY; without even the implied warranty of 
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the 
#  GNU General Public License for more details.
#
#  You should have received a copy of the GNU General Public License
#  along with this program; if not, write to the Free Software
#  Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307  USA
#
#

import urllib, logging, logging.handlers, os, random, re, signal, string, sys, time, getopt
import stat
import calendar,socket,urllib.parse
from hashlib import md5
from hashlib import sha512

#============================================================
# usage example
#
# dd_subscribe configfile.conf
#
#============================================================

try   : import amqplib.client_0_8 as amqp
except: pass

try   : import pika
except: pass

import logging, sys, time

import os,urllib,urllib.parse,sys,re

class credential_details:
      def __init__(self):
          self.url         = None
          self.ssh_keyfile = None
          self.passive     = True
          self.binary      = True
          self.tls         = False
          self.prot_p      = False
      def __str__(self):
          s  = ''
          s += self.url.geturl()
          s += " %s" % self.ssh_keyfile
          s += " %s" % self.passive
          s += " %s" % self.binary
          s += " %s" % self.tls
          s += " %s" % self.prot_p
          return s

# class credentials

class sr_credentials:

    def __init__(self, logger):
        self.logger      = logger
        self.credentials = {}
        self.pwre=re.compile(':[^/:]*@')
        
        self.logger.debug("sr_credentials __init__")

    def add(self,urlstr,details=None):

        # need to create url object
        if details == None :
           details     = credential_details()
           details.url = urllib.parse.urlparse(urlstr)

        self.credentials[urlstr] = details

    def get(self, urlstr ):
        self.logger.debug("sr_credentials get %s" % urlstr)

        # already cached

        if self.has(urlstr) :
           #self.logger.debug("sr_credentials get in cache %s %s" % (urlstr,self.credentials[urlstr]))
           return True, self.credentials[urlstr]

        # create url object if needed

        url = urllib.parse.urlparse(urlstr)

        # resolved from defined credentials

        ok, details = self.resolve(urlstr, url)
        if ok : return True, details

        # not found... is it valid ?
        if not self.isValid(url) :
           return False,None

        # cache it as is... we dont want to validate every time

        self.add(urlstr)
        self.logger.debug("sr_credentials get add %s %s" % (urlstr,self.credentials[urlstr]))
        return False,self.credentials[urlstr]

    def has(self, urlstr ):
        self.logger.debug("sr_credentials has %s" % urlstr)
        return urlstr in self.credentials

    def isTrue(self,S):
        s = S.lower()
        if  s == 'true' or s == 'yes' or s == 'on' or s == '1': return True
        return False

    def isValid(self,url,details=None):

        # network location
        if url.netloc == '' :
           # file (why here? anyway)
           if url.scheme == 'file' : return True
           return False

        # amqp... vhost not check: default / 

        # user and password provided we are ok 
        user  = url.username != None and url.username != '' 
        pasw  = url.password != None and url.password != ''
        both  = user and pasw

        # we have everything
        if both : return True

        # we have no user and no pasw (http normal, sftp hope for .ssh/config)
        if not user and not pasw :
           if url.scheme in ['http','sftp'] : return True
           return False

        #  we have a pasw no user 
        if pasw :
           # not sure... sftp hope to get user from .ssh/config 
           if url.scheme == 'sftp' : return True
           return False

        #  we only have a user ... permitted only for sftp

        if url.scheme != 'sftp' : return False

        #  sftp and an ssh_keyfile was provided... check that it exists

        if details and details.ssh_keyfile :
           if not os.path.exists(details.ssh_keyfile): return False

        #  sftp with a user (and perhaps a valid ssh_keyfile)

        return True

    def parse(self,line):
        self.logger.debug("sr_credentials parse %s" % self.pwre.sub(':<secret!>@', line, count=1) )

        try:
                sline = line.strip()
                if len(sline) == 0 or sline[0] == '#' : return
        
                # first field url string = protocol://user:password@host:port[/vost]
                parts  = sline.split()
                urlstr = parts[0]
                url    = urllib.parse.urlparse(urlstr)

                # credential details
                details     = credential_details()
                details.url = url
        
                # no option
                if len(parts) == 1 :
                   if not self.isValid(url,details) :
                      self.logger.error("bad credential 1 (%s)" % line)
                      return
                   self.add(urlstr,details)
                   return
        
                # parsing options :  comma separated option names
                # some option has name = value : like ssh_keyfile
        
                optline = sline.replace(urlstr,'')
                optline = optline.strip()
                optlist = optline.split(',')
        
                for optval in optlist:
                    parts   = optval.split('=')
                    keyword = parts[0].strip()
        
                    if    keyword == 'ssh_keyfile' : details.ssh_keyfile = parts[1].strip()
                    elif  keyword == 'passive'     : details.passive     = True
                    elif  keyword == 'active'      : details.passive     = False
                    elif  keyword == 'binary'      : details.binary      = True
                    elif  keyword == 'ascii'       : details.binary      = False
                    elif  keyword == 'ssl'         : details.tls         = False
                    elif  keyword == 'tls'         : details.tls         = True
                    elif  keyword == 'prot_p'      : details.prot_p      = True
                    else: self.logger.warning("bad credential option (%s)" % keyword)
        
                # need to check validity
                if not self.isValid(url,details) :
                   self.logger.error("bad credential 2 (%s)" % line)
                   return

                # seting options to protocol
        
                self.add(urlstr,details)
        
        except: 
                (stype, svalue, tb) = sys.exc_info()
                self.logger.error("Type: %s, Value: %s" % (stype, svalue))
                self.logger.error("sr_credentials parse %s" % line)


    def read(self,path):
        self.logger.debug("sr_credentials read")

        # read in provided credentials (not mandatory)
        try :
              if os.path.exists(path):

                 f = open(path,'r')
                 lines = f.readlines()
                 f.close

                 for line in lines :
                     self.parse(line)

        except : 
                 (stype, svalue, tb) = sys.exc_info()
                 self.logger.error("Type: %s, Value: %s" % (stype, svalue))
                 self.logger.error("sr_credentials read path = %s" % path)

        #self.logger.debug("credentials = %s\n" % self.credentials)


    def resolve(self,urlstr, url = None):

        # create url object if needed

        if not url :
           url = urllib.parse.urlparse(urlstr)

        # resolving credentials

        for s in self.credentials :
            details = self.credentials[s]
            u       = details.url

            if url.scheme        != u.scheme   : continue
            if url.hostname      != u.hostname : continue
            if url.port          != u.port     : continue
            if url.username      != u.username : 
               if url.username   != None       : continue
            if url.password      != u.password : 
               if url.password   != None       : continue

            # for AMQP...  vhost checking
            # amqp users have same credentials for any vhost
            # default /  may not be set...
            if 'amqp' in url.scheme :
                url_vhost = url.path
                u_vhost   = u.path
                if url_vhost == '' : url_vhost = '/'
                if u_vhost   == '' : u_vhost   = '/'

                if url_vhost != u_vhost : continue

            # resolved : cache it and return

            self.credentials[urlstr] = details
            #self.logger.debug("sr_credentials get resolved %s %s" % (urlstr,details))
            return True, details

        return False, None


# ==========
# message to mimic amqplib from pika
# ==========

class MY_Message:

   def __init__(self,logger):
       self.logger        = logger
       self.delivery_info = {}
       self.properties    = {}

   def pika_to_amqplib(self, method_frame, properties, body ):
       try :
               self.body  = body

               self.delivery_info['exchange']         = method_frame.exchange
               self.delivery_info['routing_key']      = method_frame.routing_key
               self.delivery_tag                      = method_frame.delivery_tag

               self.properties['application_headers'] = properties.headers
       except:
               (stype, value, tb) = sys.exc_info()
               self.logger.error("Type: %s, Value: %s" % (stype, value))
               self.logger.error("in pika to amqplib %s %s" %(vars(method_frame),vars(properties)))


# ==========
# HostConnect
# ==========

class HostConnect:

   def __init__(self, logger = None):

       self.asleep     = False
       self.loop       = True

       self.connection = None
       self.channel    = None
       self.ssl        = False

       self.logger     = logger

       self.protocol   = 'amqp'
       self.host       = 'localhost'
       self.port       = None
       self.user       = 'guest'
       self.passwd     = 'guest'

       self.rebuilds   = []
       self.toclose    = []

       self.sleeping   = None

       self.pika_available    = 'pika'    in sys.modules
       self.amqplib_available = 'amqplib' in sys.modules

       self.use_pika          = self.pika_available

   def add_build(self,func):
       self.rebuilds.append(func)

   def add_sleeping(self,func):
       self.sleeping = func
       
   def close(self):
       for channel in self.toclose:
           if self.use_pika : cid = channel.channel_number
           else:              cid = channel.channel_id
           self.logger.debug("closing channel_id: %s" % cid)
           try:    channel.close()
           except: pass
       try:    self.connection.close()
       except: pass
       self.toclose    = []
       self.connection = None

   def connect(self):

       if self.sleeping != None :
          self.asleep = self.sleeping()

       if self.asleep : return

       while True:
          try:
               # connect
               self.logger.debug("Connecting %s %s (ssl %s)" % (self.host,self.user,self.ssl) )
               host = self.host
               if self.port   != None : host = host + ':%s' % self.port
               self.logger.debug("%s://%s:<pw>@%s%s ssl=%s" % (self.protocol,self.user,host,self.vhost,self.ssl))
               if self.use_pika:
                      self.logger.debug("PIKA is used")
                      credentials = pika.PlainCredentials(self.user, self.password)
                      parameters  = pika.connection.ConnectionParameters(self.host,self.port,self.vhost,credentials,ssl=self.ssl)
                      self.connection = pika.BlockingConnection(parameters)
                      logger = logging.getLogger('pika')
                      if self.logger.level != logging.DEBUG : logger.setLevel(logging.CRITICAL)
                      else:                                   logger.setLevel(logging.WARNING)
               else:
                      self.logger.debug("AMQPLIB is used")
                      self.connection = amqp.Connection(host, userid=self.user, password=self.password, \
                                                        virtual_host=self.vhost,ssl=self.ssl)
               self.channel    = self.new_channel()
               self.logger.debug("Connected ")
               for func in self.rebuilds:
                   func()
               break
          except:
               (stype, svalue, tb) = sys.exc_info()
               self.logger.error("AMQP Sender cannot connect to: %s" % self.host)
               self.logger.error("Type=%s, Value=%s" % (stype, svalue))
               if not self.loop : sys.exit(1)
               self.logger.error("Sleeping 5 seconds ...")
               time.sleep(5)

   def exchange_declare(self,exchange,edelete=False,edurable=True):
       try    :
                    self.channel.exchange_declare(exchange, 'topic', auto_delete=edelete,durable=edurable)
                    self.logger.info("declaring exchange %s (%s@%s)" % (exchange,self.user,self.host))
       except :
                    (stype, svalue, tb) = sys.exc_info()
                    self.logger.error("could not declare exchange %s (%s@%s)" % (exchange,self.user,self.host))
                    self.logger.error("Type=%s, Value=%s" % (stype, svalue))

   def exchange_delete(self,exchange):

       # never delete basic and permanent exchanges...

       if exchange in ['xpublic','xreport'] :
          self.logger.info("exchange %s remains" % exchange)
          return

       if exchange.startswith('xwinnow') :
          self.logger.info("exchange %s remains" % exchange)
          return

       # proceed for all others
       try    :
                    self.channel.exchange_delete(exchange)
                    self.logger.info("deleting exchange %s (%s@%s)" % (exchange,self.user,self.host))
       except :
                    (stype, svalue, tb) = sys.exc_info()
                    self.logger.error("could not delete exchange %s (%s@%s)" % (exchange,self.user,self.host))
                    self.logger.error("Type=%s, Value=%s" % (stype, svalue))


   def new_channel(self):
       channel = self.connection.channel()
       self.toclose.append(channel)
       return channel

   def queue_delete(self,queue_name):
       self.logger.info("deleting queue %s (%s@%s)" % (queue_name,self.user,self.host))
       try    :
                    self.channel.queue_delete(queue_name)
       except :
                    (stype, svalue, tb) = sys.exc_info()
                    error_str = '%s' % svalue
                    if 'NOT_FOUND' in error_str : return
                    self.logger.error("could not delete queue %s (%s@%s)" % (queue_name,self.user,self.host))
                    self.logger.error("Type=%s, Value=%s" % (stype, svalue))

   def reconnect(self):
       self.close()
       self.connect()

   def set_credentials(self,protocol,user,password,host,port,vhost):
       self.protocol = protocol
       self.user     = user
       self.password = password
       self.host     = host
       self.port     = port
       self.vhost    = vhost

       if self.protocol == 'amqps' : self.ssl = True
       if self.vhost    == None    : self.vhost = '/'
       if self.vhost    == ''      : self.vhost = '/'

   def set_url(self,url):
       self.protocol = url.scheme
       self.user     = url.username
       self.password = url.password
       self.host     = url.hostname
       self.port     = url.port
       self.vhost    = url.path

       if self.protocol == 'amqps' : 
          self.ssl = True
          if self.port == None :
               self.port=5671

       if self.vhost    == None    : self.vhost = '/'
       if self.vhost    == ''      : self.vhost = '/'

   def set_pika(self,pika=True):

       self.use_pika = pika

       # good choices

       if self.pika_available    and     pika: return
       if self.amqplib_available and not pika: return

       # failback choices

       if self.pika_available    and not pika:
          self.logger.warning("amqplib unavailable : using pika")
          self.use_pika = True
          return

       if self.amqplib_available and     pika:
          self.logger.warning("pika unavailable : using amqplib")
          self.use_pika = False
          return

       # nothing available

       if not self.pika_available and not self.amqplib_available :
          self.logger.error("pika unavailable, amqplib unavailable")
          os._exit(1)


# ==========
# Consumer
# ==========

class Consumer:

   def __init__(self,hostconnect):

      self.hc       = hostconnect
      self.logger   = self.hc.logger
      self.prefetch = 20

      self.exchange_type = 'topic'

      self.hc.add_build(self.build)

      # truncated exponential backoff for consume...
      self.sleep_max  = 1
      self.sleep_min = 0.01
      self.sleep_now = self.sleep_min

      self.for_pika_msg  = None
      if self.hc.use_pika :
         self.for_pika_msg = MY_Message(self.logger)

   def add_prefetch(self,prefetch):
       self.prefetch = prefetch

   def build(self):
       self.logger.debug("building consumer")
       self.channel = self.hc.new_channel()
       if self.prefetch != 0 :
          prefetch_size = 0      # dont care
          a_global      = False  # only apply here
          self.channel.basic_qos(prefetch_size,self.prefetch,a_global)
       
   def ack(self,msg):
       self.logger.debug("--------------> ACK")
       self.logger.debug("--------------> %s" % msg.delivery_tag )
       self.channel.basic_ack(msg.delivery_tag)

   def consume(self,queuename):

       msg = None

       if not self.hc.asleep :
              try :
                      if self.hc.use_pika :
                           self.logger.debug("consume PIKA is used")
                           method_frame, properties, body = self.channel.basic_get(queuename)
                           if method_frame and properties and body :
                              self.for_pika_msg.pika_to_amqplib(method_frame, properties, body )
                              msg = self.for_pika_msg
                      else:
                              self.logger.debug("consume AMQPLIB is used")
                              msg = self.channel.basic_get(queuename)
              except :
                     (stype, value, tb) = sys.exc_info()
                     self.logger.error("Type: %s, Value: %s" % (stype, value))
                     self.logger.error("Could not consume in queue %s" % queuename )
                     if self.hc.loop :
                        self.hc.reconnect()
                        self.logger.debug("consume resume ok")
                        if not self.hc.asleep : msg = self.consume(queuename)
       else:
              time.sleep(5)

       # when no message sleep for 1 sec. (value taken from old metpx)
       # *** value 0.01 was tested and would simply raise cpu usage of broker
       # to unacceptable level with very fews processes (~20) trying to consume messages
       # remember that instances and broker sharing messages add up to a lot of consumers

       if msg == None : 
          #self.logger.debug(" no messages received, sleep %5.2fs" % self.sleep_now)
          time.sleep(self.sleep_now)
          self.sleep_now = self.sleep_now * 2
          if self.sleep_now > self.sleep_max : 
                 self.sleep_now = self.sleep_max

       if msg != None :
          self.sleep_now = self.sleep_min 
          #self.logger.debug("--------------> GOT")

       return msg

# ==========
# Publisher
# ==========

class Publisher:

   def __init__(self,hostconnect):
       self.hc     = hostconnect
       self.logger = self.hc.logger
       self.hc.add_build(self.build)

   def build(self):
       self.channel = self.hc.new_channel()
       if self.hc.use_pika :  self.channel.confirm_delivery()
       else:                  self.channel.tx_select()
       
   def publish(self,exchange_name,exchange_key,message,mheaders):
       try :
              if self.hc.use_pika :
                     self.logger.debug("publish PIKA is used")
                     properties = pika.BasicProperties(content_type='text/plain', delivery_mode=1, headers=mheaders)
                     self.channel.basic_publish(exchange_name, exchange_key, message, properties, True )
              else:
                     self.logger.debug("publish AMQPLIB is used")
                     msg = amqp.Message(message, content_type= 'text/plain',application_headers=mheaders)
                     self.channel.basic_publish(msg, exchange_name, exchange_key )
                     self.channel.tx_commit()
              return True
       except :
              if self.hc.loop :
                 (stype, value, tb) = sys.exc_info()
                 self.logger.error("Type: %s, Value: %s" % (stype, value))
                 self.logger.error("Sleeping 5 seconds ... and reconnecting")
                 time.sleep(5)
                 self.hc.reconnect()
                 if self.hc.asleep : return False
                 return self.publish(exchange_name,exchange_key,message,mheaders)
              else:
                 (etype, evalue, tb) = sys.exc_info()
                 self.logger.error("Type: %s, Value: %s" %  (etype, evalue))
                 self.logger.error("could not publish %s %s %s %s" % (exchange_name,exchange_key,message,mheaders))
                 return False


# ==========
# Queue
# ==========

class Queue:

   def __init__(self,hc,qname,auto_delete=False,durable=False,reset=False):

       self.hc          = hc
       self.logger      = self.hc.logger
       self.name        = qname
       self.qname       = qname
       self.auto_delete = False
       self.durable     = durable
       self.reset       = reset

       self.expire      = 0
       self.message_ttl = 0

       self.bindings    = []

       self.hc.add_build(self.build)

   def add_binding(self,exchange_name,exchange_key):
       self.bindings.append( (exchange_name,exchange_key) )

   def add_expire(self, expire):
       self.expire = expire

   def add_message_ttl(self, message_ttl):
       self.message_ttl = message_ttl

   def bind(self, exchange_name,exchange_key):
       self.channel.queue_bind(self.qname, exchange_name, exchange_key )

   def build(self):
       self.logger.debug("building queue %s" % self.name)
       self.channel = self.hc.new_channel()

       # queue arguments
       args = {}
       if self.expire      > 0 : args['x-expires']     = self.expire
       if self.message_ttl > 0 : args['x-message-ttl'] = self.message_ttl

       # reset 
       if self.reset :
          try    : self.channel.queue_delete( self.name )
          except : self.logger.debug("could not delete queue %s (%s@%s)" % (self.name,self.hc.user,self.hc.host))
                  
       # create queue
       try:
           if self.hc.use_pika:
                  self.logger.debug("queue_declare PIKA is used")
                  q_dclr_ok = self.channel.queue_declare( self.name,
                                       passive=False, durable=self.durable, exclusive=False,
                                       auto_delete=self.auto_delete,
                                       arguments= args )

                  method = q_dclr_ok.method

                  self.qname, msg_count, consumer_count = method.queue, method.message_count, method.consumer_count

           else:
                  self.logger.debug("queue_declare AMQPLIB is used")
                  self.qname, msg_count, consumer_count = \
                      self.channel.queue_declare( self.name,
                                          passive=False, durable=self.durable, exclusive=False,
                                          auto_delete=self.auto_delete,
                                          nowait=False,
                                          arguments= args )
       except : 
              self.logger.error( "queue declare: %s failed...(%s@%s) permission issue ?" % (self.name,self.hc.user,self.hc.host))
              (stype, svalue, tb) = sys.exc_info()
              self.logger.error("Type: %s, Value: %s" %  (stype, svalue))

       # queue bindings
       for exchange_name,exchange_key in self.bindings:
           self.logger.debug("binding queue to exchange=%s with key=%s" % (exchange_name,exchange_key))
           try:
              self.bind(exchange_name, exchange_key )
           except : 
              self.logger.error( "bind queue: %s to exchange: %s with key: %s failed.." % \
                                 (self.name,exchange_name, exchange_key ) )
              self.logger.error( "Permission issue with %s@%s or exchange %s not found." % \
                                 (self.hc.user,self.hc.host,exchange_name ) )

       self.logger.debug("queue build done")


class sr_file():
    def __init__(self, parent) :
        parent.logger.debug("sr_file __init__")

        self.logger      = parent.logger
        self.parent      = parent 

    # cd
    def cd(self, path):
        self.logger.debug("sr_file cd %s" % path)
        os.chdir(path)
        self.path = path

    # chmod
    def chmod(self,perm,path):
        self.logger.debug("sr_file chmod %s %s" % ( "{0:o}".format(perm),path))
        os.chmod(path,perm)

    # close
    def close(self):
        self.logger.debug("sr_file close")
        return

    # connect
    def connect(self):
        self.logger.debug("sr_file connect %s" % self.parent.destination)

        self.recursive   = True
        self.destination = self.parent.destination
        self.timeout     = self.parent.timeout

        self.kbytes_ps = 0
        self.bufsize   = 8192

        if hasattr(self.parent,'kbytes_ps') : self.kbytes_ps = self.parent.kbytes_ps
        if hasattr(self.parent,'bufsize')   : self.bufsize   = self.parent.bufsize

        self.connected   = True

        return True

    # delete
    def delete(self, path):
        self.logger.debug("sr_file rm %s" % path)
        os.unlink(path)

    # ls
    def ls(self):
        self.logger.debug("sr_file ls")
        self.entries  = {}
        self.root = self.path
        self.ls_python(self.path)
        return self.entries

    def ls_python(self,dpath):
        for x in os.listdir(dpath):
            dst = dpath + os.sep + x
            if os.path.isdir(dst):
               if self.recursive : self.ls_python(dst)
               continue
            relpath = dst.replace(self.root,'',1)
            if relpath[0] == '/' : relpath = relpath[1:]

            lstat = os.stat(dst)
            line  = stat.filemode(lstat.st_mode)
            line += ' %d %d %d' % (lstat.st_nlink,lstat.st_uid,lstat.st_gid)
            line += ' %d' % lstat.st_size
            line += ' %s' % time.strftime("%b %d %H:%M", time.localtime(lstat.st_mtime))
            line += ' %s' % relpath
            self.entries[relpath] = line



# file_insert
# called by file_process (general file:// processing)

def file_insert( parent,msg ) :
    parent.logger.debug("file_insert")

    # file must exists
    if not os.path.isfile(msg.relpath):
       fp = open(msg.relpath,'w')
       fp.close()

    fp = open(msg.relpath,'r+b')
    if msg.partflg == 'i' : fp.seek(msg.offset,0)

    ok = file_write_length(fp, msg, parent.bufsize, msg.filesize )

    fp.close()

    return ok


# file_insert_part
# called by file_reassemble : rebuiding file from parts
#
# when inserting, anything that goes wrong means that
# another process is working with this part_file
# so errors are ignored silently 

def file_insert_part(parent,msg,part_file):
    parent.logger.debug("file_insert_part %s" % part_file)
    chk = msg.sumalgo
    try :
             # file disappeared ...
             # probably inserted by another process in parallel
             if not os.path.isfile(part_file):
                parent.logger.debug("file doesnt exist %s" % part_file)
                return False

             # file with wrong size
             # probably being written now by another process in parallel

             lstat    = os.stat(part_file)
             fsiz     = lstat[stat.ST_SIZE] 
             if fsiz != msg.length : 
                parent.logger.debug("file wrong size %s %d %d" % (part_file,fsiz,msg.length))
                return False

             # proceed with insertion

             fp = open(part_file,'rb')
             ft = open(msg.target_file,'r+b')
             ft.seek(msg.offset,0)

             # no worry with length, read all of part_file
             # compute onfly_checksum ...

             bufsize = parent.bufsize
             if bufsize > msg.length : bufsize = msg.length

             if chk : chk.set_path(os.path.basename(msg.target_file))

             i  = 0
             while i<msg.length :
                   buf = fp.read(bufsize)
                   if not buf: break
                   ft.write(buf)
                   if chk : chk.update(buf)
                   i  += len(buf)

             if ft.tell() >= msg.filesize:
                 ft.truncate()

             ft.close() 
             fp.close()

             if i != msg.length :
                msg.logger.error("file_insert_part file currupted %s" % part_file)
                msg.logger.error("read up to  %d of %d " % (i,msg.length) )
                lstat   = os.stat(part_file)
                fsiz    = lstat[stat.ST_SIZE] 
                msg.logger.error("part filesize  %d " % (fsiz) )

             # set checksum in msg
             if chk : msg.onfly_checksum = chk.get_value()

             # remove inserted part file

             try    : os.unlink(part_file)
             except : pass

             # run on part... if provided

             if parent.on_part :
                ok = parent.on_part(parent)
                if not ok : 
                   msg.logger.warning("inserted but rejected by on_part %s " % part_file)
                   msg.logger.warning("the file may not be correctly reassemble %s " % msg.target_file)
                   return ok

    # oops something went wrong

    except :
             (stype, svalue, tb) = sys.exc_info()
             msg.logger.debug("Type: %s, Value: %s,  ..." % (stype, svalue))
             msg.logger.debug("did not insert %s " % part_file)
             return False

    # success: log insertion

    msg.report_publish(201,'Inserted')

    # publish now, if needed, that it is inserted

    if msg.publisher : 
       msg.set_topic('v02.post',msg.target_relpath)
       msg.set_notice(msg.new_baseurl,msg.target_relpath,msg.time)
       if chk :
          if    msg.sumflg == 'z' :
                msg.set_sum(msg.checksum,msg.onfly_checksum)
          else: msg.set_sum(msg.sumflg,  msg.onfly_checksum)

       parent.__on_post__()
       msg.report_publish(201,'Publish')

    # if lastchunk, check if file needs to be truncated
    file_truncate(parent,msg)

    # ok we reassembled the file and it is the last chunk... call on_file
    if msg.lastchunk : 
       msg.logger.warning("file assumed complete with last part %s" % msg.target_file)
       #if parent.on_file:
       #   ok = parent.on_file(parent)
       for plugin in parent.on_file_list:
          ok = plugin(parent)
          if not ok: return False

    return True


# file_link
# called by file_process (general file:// processing)

def file_link( msg ) :

    try    : os.unlink(msg.new_file)
    except : pass
    try    : os.link(msg.relpath,msg.new_file)
    except : return False

    msg.compute_local_checksum()
    msg.onfly_checksum = msg.local_checksum

    msg.report_publish( 201, 'Linked')

    return True

# file_process (general file:// processing)

def file_process( parent ) :
    parent.logger.debug("file_process")

    msg = parent.msg

    try:    curdir = os.getcwd()
    except: curdir = None

    if curdir != parent.new_dir:
       os.chdir(parent.new_dir)

    # try link if no inserts

    if msg.partflg == '1' or \
       (msg.partflg == 'p' and  msg.in_partfile) :
       ok = file_link(msg)
       if ok :
          if parent.delete :
              try: 
                  os.unlink(msg.relpath)
              except: 
                  msg.logger.error("delete of link to %s failed"%(msg.relpath))
          return ok

    # This part is for 2 reasons : insert part
    # or copy file if preceeding link did not work
    try :
             ok = file_insert(parent,msg)
             if parent.delete :
                if msg.partflg.startswith('i'):
                   msg.logger.info("delete unimplemented for in-place part files %s" %(msg.relpath))
                else:
                   try: 
                       os.unlink(msg.relpath)
                   except: 
                       msg.logger.error("delete of %s after copy failed"%(msg.relpath))

             if ok : return ok

    except : 
             (stype, svalue, tb) = sys.exc_info()
             msg.logger.debug("Type: %s, Value: %s,  ..." % (stype, svalue))

    msg.report_publish(499,'Not Copied')
    msg.logger.error("could not copy %s in %s"%(msg.relpath,msg.new_file))

    return False

# file_reassemble : rebuiding file from parts
# when ever a part file is processed (inserted or written in part_file)
# this module is called to try inserting any part_file left

def file_reassemble(parent):
    parent.logger.debug("file_reassemble")

    msg = parent.msg

    if not hasattr(msg,'target_file') or msg.target_file == None : return

    try:    curdir = os.getcwd()
    except: curdir = None

    if curdir != parent.new_dir:
       os.chdir(parent.new_dir)

    # target file does not exit yet

    if not os.path.isfile(msg.target_file) :
       msg.logger.debug("insert_from_parts: target_file not found %s" % msg.target_file)
       return

    # check target file size and pick starting part from that

    lstat   = os.stat(msg.target_file)
    fsiz    = lstat[stat.ST_SIZE] 
    i       = int(fsiz /msg.chunksize)

    msg.logger.debug("verify ingestion : block = %d of %d" % (i,msg.block_count))
       
    while i < msg.block_count:

          # setting block i in message

          msg.current_block = i
          msg.set_parts('i',msg.chunksize,msg.block_count,msg.remainder,msg.current_block)
          msg.set_suffix()

          # set part file

          part_file = msg.target_file + msg.suffix
          if not os.path.isfile(part_file) :
             msg.logger.debug("part file %s not found, stop insertion" % part_file)
             # break and not return because we want to check the lastchunk processing
             break

          # check for insertion (size may have changed)

          lstat   = os.stat(msg.target_file)
          fsiz    = lstat[stat.ST_SIZE] 
          if msg.offset > fsiz :
             msg.logger.debug("part file %s no ready for insertion (fsiz %d, offset %d)" % (part_file,fsiz,msg.offset))
             break


          # insertion attempt... should work unless there is some race condition

          ok = file_insert_part(parent,msg,part_file)
          # break and not return because we want to check the lastchunk processing
          if not ok : break
          i = i + 1

    # if lastchunk, check if file needs to be truncated
    file_truncate(parent,msg)



# file_write_length
# called by file_process->file_insert (general file:// processing)

def file_write_length(req,msg,bufsize,filesize):
    msg.logger.debug("file_write_length")

    msg.onfly_checksum = None

    chk = msg.sumalgo
    msg.logger.debug("file_write_length chk = %s" % chk)
    if chk : chk.set_path(msg.new_file)

    # file should exists
    if not os.path.isfile(msg.new_file) :
       fp = open(msg.new_file,'w')
       fp.close()

    # file open read/modify binary
    fp = open(msg.new_file,'r+b')
    if msg.local_offset != 0 : fp.seek(msg.local_offset,0)

    nc = int(msg.length/bufsize)
    r  =     msg.length%bufsize

    # read/write bufsize "nc" times
    i  = 0
    while i < nc :
          chunk = req.read(bufsize)
          fp.write(chunk)
          if chk : chk.update(chunk)
          i = i + 1

    # remaining
    if r > 0 :
       chunk = req.read(r)
       fp.write(chunk)
       if chk : chk.update(chunk)

    if fp.tell() >= msg.filesize:
       fp.truncate()

    fp.close()
  
    h = self.parent.msg.headers
    if self.parent.preserve_mode and 'mode' in h :
       try   : mod = int( h['mode'], base=8)
       except: mod = 0
       if mod > 0 : os.chmod(msg.new_file, mod )

    if self.parent.preserve_time and 'mtime' in h and h['mtime'] :
        os.utime(msg.new_file, times=( timestr2flt( h['atime']), timestr2flt( h[ 'mtime' ] )))

    if chk : msg.onfly_checksum = chk.get_value()

    msg.report_publish(201,'Copied')

    return True

# file_truncate
# called under file_reassemble (itself and its file_insert_part)
# when inserting lastchunk, file may need to be truncated

def file_truncate(parent,msg):

    # will do this when processing the last chunk
    # whenever that is
    if not msg.lastchunk : return

    try :
             lstat   = os.stat(msg.target_file)
             fsiz    = lstat[stat.ST_SIZE] 

             if fsiz > msg.filesize :
                fp = open(msg.target_file,'r+b')
                fp.truncate(msg.filesize)
                fp.close()

                msg.set_topic('v02.post',msg.target_relpath)
                msg.set_notice(msg.new_baseurl,msg.target_relpath,msg.time)
                msg.report_publish(205, 'Reset Content :truncated')

    except : pass


# AMQP limits headers to 'short string', or 255 characters, so truncate and warn.
amqp_ss_maxlen = 253

class sr_message():

    def __init__(self,parent):
        self.parent        = parent
        self.logger        = parent.logger

        self.bufsize       = parent.bufsize

        self.exchange      = None
        self.report_exchange  = 'xreport'
        self.report_publisher = None
        self.publisher     = None
        self.pub_exchange  = None
        self.topic         = None
        self.notice        = None
        self.headers       = {}

        self.partstr       = None
        self.sumstr        = None
        self.sumflg        = None

        self.part_ext      = 'Part'

        self.sumalgo       = parent.sumalgo

        self.inplace       = True

        self.user          = None

        self.host          = socket.getfqdn()

        self.add_headers   = self.parent.headers_to_add
        self.del_headers   = self.parent.headers_to_del

    def change_partflg(self, partflg ):
        self.partflg       =  partflg 
        self.partstr       = '%s,%d,%d,%d,%d' %\
                             (partflg,self.chunksize,self.block_count,self.remainder,self.current_block)

    def content_should_not_be_downloaded(self):
        """
        if the file advertised is newer than the local one, and it has a different checksum, return True.

        """
        self.logger.debug("sr_message content_match")
        self.local_checksum = None

        if not os.path.isfile(self.new_file) : return False

        # insert : file big enough to compute part checksum ?

        lstat = os.stat(self.new_file)
        fsiz  = lstat[stat.ST_SIZE] 
        end   = self.local_offset + self.length

        # compare dates...

        if self.parent.preserve_time and 'mtime' in self.headers:
            new_mtime = timestr2flt(self.headers[ 'mtime' ])
            if new_mtime <= lstat[stat.ST_MTIME]:
               return True

        if self.sumflg in ['0','n','z'] : 
            return False
 
        if end > fsiz :
           self.logger.warning("sr_message content_match file not big enough (insert?)")
           return False

        self.compute_local_checksum()

        return self.local_checksum == self.checksum

    def compute_local_checksum(self):
        self.logger.debug("sr_message compute_local_checksum")

        bufsize = self.bufsize
        if self.length < bufsize : bufsize = self.length

        self.sumalgo.set_path(os.path.basename(self.new_file))

        fp = open(self.new_file,'rb')
        if self.local_offset != 0 : fp.seek(self.local_offset,0)
        i  = 0
        while i<self.length :
              buf = fp.read(bufsize)
              if not buf: break
              self.sumalgo.update(buf)
              i  += len(buf)
        fp.close()

        if i != self.length :
           self.logger.warning("sr_message compute_local_checksum incomplete reading %d %d" % (i,self.length))
           self.local_checksum = '0'
           return

        self.local_checksum = self.sumalgo.get_value()


    def from_amqplib(self, msg=None ):

        self.start_timer()

        #self.logger.debug("attributes= %s" % vars(msg))
        if msg :
           self.exchange  = msg.delivery_info['exchange']
           self.topic     = msg.delivery_info['routing_key']
           self.headers   = msg.properties['application_headers']
           self.notice    = msg.body

           if type(msg.body) == bytes: self.notice = msg.body.decode("utf-8")

        # retransmission case :
        # topic is name of the queue...
        # set exchange to xpublic
        # rebuild topic from notice : v02.post....

        if self.exchange == '' and self.topic[:2] == 'q_':
           self.logger.debug(" retransmit topic = %s" % self.topic)
           token = self.notice.split(' ')
           self.exchange = 'xpublic'
           if hasattr(self.headers,'exchange') :
              self.exchange = self.headers['exchange']
              del self.headers['exchange']

           path  = token[2].strip('/')
           words = path.split('/')
           self.topic    = 'v02.post.' + '.'.join(words[:-1])
           self.logger.debug(" modified for topic = %s" % self.topic)

        # adjust headers from -headers option

        self.trim_headers()

        self.partstr     = None
        self.sumstr      = None

        token        = self.topic.split('.')
        self.version = token[0]

        if self.version == 'v00' :
           self.parse_v00_post()

        if self.version == 'v02' :
           self.parse_v02_post()

    def get_elapse(self):
        return time.time()-self.tbegin

    def report_publish(self,code,message):
        self.code               = code
        self.headers['message'] = message
        self.report_topic          = self.topic.replace('.post.','.report.')
        self.report_notice         = "%s %d %s %s %f" % \
                                  (self.notice,self.code,self.host,self.user,self.get_elapse())
        self.set_hdrstr()

        # AMQP limits topic to 255 characters, so truncate and warn.
        if len(self.topic.encode("utf8")) >= amqp_ss_maxlen :
           mxlen=amqp_ss_maxlen 
           # see truncation explanation from above.
           while( self.report_topic.encode("utf8")[mxlen-1] & 0xc0 == 0xc0 ):
               mxlen -= 1

           self.report_topic = self.report_topic.encode("utf8")[0:mxlen].decode("utf8")
           self.logger.warning( "truncating reporting topic at %d characters (to fit 255 byte AMQP limit) to: %s " % \
                        ( len(self.report_topic) , self.report_topic ) )

        if self.report_publisher != None :
           self.report_publisher.publish(self.report_exchange,self.report_topic,self.report_notice,self.headers)

        self.logger.debug("%d %s : %s %s %s" % (code,message,self.report_topic,self.report_notice,self.hdrstr))

        # make sure not published again
        del self.headers['message']

    def parse_v00_post(self):
        token             = self.topic.split('.')
        # v00             = token[0]
        # dd              = token[1]
        # notify          = token[2]
        self.version      = 'v02'
        self.mtype        = 'post'
        self.topic_prefix = 'v02.post'
        self.subtopic     = '.'.join(token[3:])
        self.topic        = self.topic_prefix + '.' + self.subtopic

        token        = self.notice.split(' ')
        self.baseurl = token[2]
        self.relpath = token[3].replace('%20',' ')

        self.set_notice(token[2],token[3])

        url          = urllib.parse.urlparse(token[2]+token[3])
        
        self.checksum = token[0]
        self.filesize = int(token[1])

        self.headers['source'] = 'metpx'

        self.partstr = '1,%d,1,0,0' % self.filesize
        self.headers['parts'] = self.partstr

        self.sumstr  = 'd,%s' % self.checksum
        self.headers['sum'] = self.sumstr

        self.to_clusters = []
        self.headers['to_clusters'] = None

        self.suffix  = ''
        
        self.set_parts_str(self.partstr)
        self.set_sum_str(self.sumstr)
        self.set_suffix()
        self.set_hdrstr()

    def parse_v02_post(self):

        token         = self.topic.split('.')
        self.version  = token[0]
        self.mtype    = token[1]
        self.topic_prefix = '.'.join(token[:2])
        self.subtopic     = '.'.join(token[3:])

        token        = self.notice.split(' ')
        self.time    = token[0]
        self.baseurl = token[1]
        self.relpath = token[2].replace('%20',' ')
        self.urlstr  = token[1]+token[2]
        self.url     = urllib.parse.urlparse(self.urlstr)

        if self.mtype == 'report' or self.mtype == 'log': # log included for compatibility... prior to rename..
           self.report_code   = int(token[3])
           self.report_host   = token[4]
           self.report_user   = token[5]
           self.report_elapse = float(token[6])

        self.partstr = None
        if 'parts'   in self.headers :
           self.partstr  = self.headers['parts']

        self.sumstr  = None
        if 'sum'     in self.headers :
           self.sumstr   = self.headers['sum']

        self.to_clusters = []
        if 'to_clusters' in self.headers :
           self.to_clusters  = self.headers['to_clusters'].split(',')

        self.suffix = ''

        self.set_parts_str(self.partstr)
        self.set_sum_str(self.sumstr)
        self.set_suffix()
        self.set_msg_time()
        self.set_hdrstr()

    def part_suffix(self):
        return '.%d.%d.%d.%d.%s.%s' %\
               (self.chunksize,self.block_count,self.remainder,self.current_block,self.sumflg,self.part_ext)

    def publish(self):
        ok = False

        if self.pub_exchange != None : self.exchange = self.pub_exchange

        for h in self.headers:
           if len(self.headers[h].encode("utf8")) >= amqp_ss_maxlen:

                # strings in utf, and if names have special characters, the length
                # of the encoded string wll be longer than what is returned by len(. so actually need to look
                # at the encoded length ...  len ( self.headers[h].encode("utf-8") ) < 255
                # but then how to truncate properly. need to avoid invalid encodings.
                mxlen=amqp_ss_maxlen
                while( self.headers[h].encode("utf8")[mxlen-1] & 0xc0 == 0xc0 ):
                      mxlen -= 1

                self.headers[h] = self.headers[h].encode("utf8")[0:mxlen].decode("utf8")
                self.logger.warning( "truncating %s header at %d characters (to fit 255 byte AMQP limit) to: %s " % \
                        ( h, len(self.headers[h]) , self.headers[h]) )
                
        # AMQP limits topic to 255 characters, so truncate and warn.
        if len(self.topic.encode("utf8")) >= amqp_ss_maxlen :
           mxlen=amqp_ss_maxlen 
           # see truncation explanation from above.
           while( self.topic.encode("utf8")[mxlen-1] & 0xc0 == 0xc0 ):
               mxlen -= 1

           self.topic = self.topic.encode("utf8")[0:mxlen].decode("utf8")
           self.logger.warning( "truncating topic at %d characters (to fit 255 byte AMQP limit) to: %s " % \
                        ( len(self.topic) , self.topic ) )
        

        # in order to split winnowing into multiple instances, directs items with same checksum
        # to same shard. do that by keying on the last character of the checksum.
        # 
        if self.post_exchange_split > 0 :
           suffix= "%02d" % ( ord(self.sumstr[-1]) % self.post_exchange_split )
           self.logger.debug( "post_exchange_split set, keying on %s , suffix is %s" % ( self.sumstr[-1], suffix) )
        else:
           suffix=""

        if self.publisher != None :
           ok = self.publisher.publish(self.exchange+suffix,self.topic,self.notice,self.headers)

        self.set_hdrstr()

        if ok :
                self.logger.debug("Published1: %s %s" % (self.exchange,self.topic))
                self.logger.debug("Published2: '%s' %s" % (self.notice, self.hdrstr))
        else  :
                self.printlog = self.logger.error
                self.printlog("Could not publish message :")

                self.printlog("exchange %s topic %s " % (self.exchange,self.topic))
                self.printlog("notice   %s"           % self.notice )
                self.printlog("headers  %s"           % self.hdrstr )

        return ok

    def set_exchange(self,name):
        self.exchange = name

    def set_file(self, new_file, sumstr):
        """ 
            set_file: modify a message to reflect a new file.
                      make a file URL of the new_file.
            sumstr should be the properly formatted checksum field for a message
              '<algorithm>,<value>', e.g.  'd,cbe9047d1b979561bed9a334111878c6'
            to be used by filter plugins when changing the output url.
        """
        fstat = os.stat(new_file)

        # Modify message for posting.

        self.baseurl = 'file:'
        self.relpath = new_file

        self.urlstr = 'file:/' + new_file
        self.url = urllib.parse.urlparse(self.urlstr)

        path  = new_file.strip('/')
        words = path.split('/')
        self.topic = 'v02.post.' + '.'.join(words[:-1])

        self.headers[ 'sum' ] = sumstr
        self.headers[ 'parts' ] = '1,%d,0,0' % fstat.st_size
        self.headers[ 'mtime' ] = timeflt2str(fstat.st_mtime)

        self.set_notice(self.baseurl,self.relpath)

    def set_hdrstr(self):
        self.hdrstr  = ''

        for h in self.headers:
           self.hdrstr += '%s=%s ' % (h, self.headers[h])

        # added for v00 compatibility (old version of dd_subscribe)
        # can be taken off when v02 will be fully deployed and end user uses sr_subscribe
        #self.headers['filename'] = os.path.basename(self.relpath).split(':')[0][0:200]


    # Once we know the local file we want to use
    # we can have a few flavor of it

    def set_new(self):

        self.local_offset  = 0
        self.in_partfile   = False
        self.local_checksum= None
       
        self.inplace       = self.parent.inplace
        self.new_dir       = self.parent.new_dir
        self.new_file      = self.parent.new_file
        self.new_baseurl   = self.parent.new_baseurl
        self.new_relpath   = self.parent.new_relpath

        self.target_file   = None

        # file to file

        if self.partflg == '1' : return
        if self.partflg == None : return
     
        # part file never inserted

        if not self.inplace :

           self.in_partfile = True

           # part file to part file

           if self.partflg == 'p' : return

           # file inserts to part file

           if self.partflg == 'i' :
              self.new_file    += self.suffix
              self.new_relpath += self.suffix
              return

        
        # part file inserted

        if self.inplace :

           # part file inserts to file (maybe in file, maybe in part file)

           if self.partflg == 'p' :
              self.target_file    = self.new_file.replace(self.suffix,'')
              self.target_relpath = self.new_relpath.replace(self.suffix,'')
              part_file    = self.new_file
              part_relpath = self.new_relpath

        
           # file insert inserts into file (maybe in file, maybe in part file)

           if self.partflg == 'i' :
              self.target_file    = self.new_file
              self.target_relpath = self.new_relpath
              part_file           = self.new_file + self.suffix
              part_relpath        = self.new_relpath + self.suffix

           # default setting : redirect to temporary part file

           self.new_file    = part_file
           self.new_relpath = part_relpath
           self.in_partfile = True
        
           # try to make this message a file insert

           # file exists
           self.target_path = self.new_dir + os.sep + self.target_file
           if os.path.isfile(self.target_path) :
              self.logger.debug("new_file exists")
              lstat   = os.stat(self.target_path)
              fsiz    = lstat[stat.ST_SIZE] 

              self.logger.debug("offset vs fsiz %d %d" % (self.offset,fsiz ))
              # part/insert can be inserted 
              if self.offset <= fsiz :
                 self.logger.debug("insert")
                 self.new_file     = self.target_file
                 self.new_relpath  = self.target_relpath
                 self.local_offset = self.offset
                 self.in_partfile  = False
                 return

              # in temporary part file
              self.logger.debug("exist but no insert")
              return


           # file does not exists but first part/insert ... write directly to new_file
           elif self.current_block == 0 :
              self.logger.debug("not exist but first block")
              self.new_file    = self.target_file
              self.new_relpath = self.target_relpath
              self.in_partfile = False
              return

           # file does not exists any other part/insert ... put in temporary part_file
           else :
              self.logger.debug("not exist and not first block")
              self.in_partfile = True
              return
                 
        # unknow conditions

        self.logger.error("bad unknown conditions")
        return

    def set_msg_time(self):
        parts       = self.time.split('.')
        ts          = time.strptime(parts[0], "%Y%m%d%H%M%S" )
        ep_msg      = calendar.timegm(ts)
        self.tbegin = ep_msg + int(parts[1]) / 1000.0

    def set_notice_url(self,url,time=None):
        self.url    = url
        self.time   = time
        if time    == None : self.set_time()
        path        = url.path.strip('/')
        notice_path = path.replace(' ','%20')

        if url.scheme == 'file' :
           self.notice = '%s %s %s' % (self.time,'file:','/'+notice_path)
           return

        urlstr      = url.geturl()
        static_part = urlstr.replace(url.path,'') + '/'

        if url.scheme == 'http' :
           self.notice = '%s %s %s' % (self.time,static_part,notice_path)
           return

        if url.scheme[-3:] == 'ftp'  :
           if url.path[:2] == '//'   : notice_path = '/' + notice_path

        self.notice = '%s %s %s' % (self.time,static_part,notice_path)

    def set_notice(self,baseurl,relpath,time=None):

        self.time    = time
        self.baseurl = baseurl
        self.relpath = relpath
        if not time  : self.set_time()

        notice_relpath = relpath.replace(' ','%20')

        self.notice = '%s %s %s' % (self.time,baseurl,notice_relpath)

        #========================================
        # COMPATIBILITY TRICK  for the moment

        self.urlstr  = baseurl+notice_relpath
        self.url     = urllib.parse.urlparse(self.urlstr)
        #========================================


    def set_parts(self,partflg='1',chunksize=0, block_count=1, remainder=0, current_block=0):
        self.partflg          = partflg 
        self.chunksize        = chunksize
        self.block_count      = block_count
        self.remainder        = remainder
        self.current_block    = current_block
        self.partstr          = '%s,%d,%d,%d,%d' %\
                                (partflg,chunksize,block_count,remainder,current_block)
        self.lastchunk        = current_block == block_count-1
        self.headers['parts'] = self.partstr

        self.offset        = self.current_block * self.chunksize
        self.filesize      = self.block_count * self.chunksize
        if self.remainder  > 0 :
           self.filesize  += self.remainder   - self.chunksize
           if self.lastchunk : self.length    = self.remainder

    def set_parts_str(self,partstr):

        self.partflg = None
        self.partstr = partstr

        if self.partstr == None : return

        token        = self.partstr.split(',')
        self.partflg = token[0]

        self.chunksize     = int(token[1])
        self.block_count   = 1
        self.remainder     = 0
        self.current_block = 0
        self.lastchunk     = True

        self.offset        = 0
        self.length        = self.chunksize

        self.filesize      = self.chunksize

        if self.partflg in [ '0', '1' ]: return

        self.block_count   = int(token[2])
        self.remainder     = int(token[3])
        self.current_block = int(token[4])
        self.lastchunk     = self.current_block == self.block_count-1

        self.offset        = self.current_block * self.chunksize

        self.filesize      = self.block_count * self.chunksize

        if self.remainder  > 0 :
           self.filesize  += self.remainder   - self.chunksize
           if self.lastchunk : self.length    = self.remainder

    def set_rename(self,rename=None):
        if rename != None :
           self.headers['rename'] = rename
        elif 'rename' in self.headers :
           del self.headers['rename']

    def set_source(self,source=None):
        if source != None :
           self.headers['source'] = source
        elif 'source' in self.headers :
           del self.headers['source']

    def set_sum(self,sumflg='d',checksum=0):
        self.sumflg   =  sumflg
        self.checksum =  checksum
        self.sumstr   = '%s,%s' % (sumflg,checksum)
        self.headers['sum'] = self.sumstr

    def set_sum_str(self,sumstr):
        self.sumflg  = None
        self.sumalgo = None
        self.sumstr  = sumstr
        if sumstr == None : return

        token        = self.sumstr.split(',')
        self.sumflg  = token[0]
        self.checksum= token[1]

        # file to be removed
        if self.sumflg == 'R' : return

        # keep complete z description in sumflg
        if self.sumflg == 'z':
           self.sumflg  = sumstr

        self.parent.set_sumalgo(self.sumflg)
        self.sumalgo = self.parent.sumalgo

    def set_suffix(self):
        if self.partstr == None : return
        if self.sumstr  == None or self.sumflg == 'R' : return
        self.suffix = self.part_suffix()

    def set_time(self):
        now  = time.time()
        msec = '.%d' % (int(round(now * 1000)) %1000)
        nows = time.strftime("%Y%m%d%H%M%S",time.gmtime()) + msec
        self.time = nows
        if not hasattr(self,'tbegin') : self.tbegin = now

    def set_to_clusters(self,to_clusters=None):
        if to_clusters != None :
           self.headers['to_clusters'] = to_clusters
           self.to_clusters = to_clusters.split(',')
        elif 'to_clusters' in self.headers :
           del self.headers['to_clusters']
           self.to_clusters = []

    def set_topic(self,topic_prefix,relpath):
        self.topic_prefix = topic_prefix
        self.topic        = topic_prefix
        self.subtopic     = ''

        strpath           = relpath.strip('/')
        words             = strpath.split('/')
        if len(words) > 1 :
           self.subtopic = '.'.join(words[:-1])
           self.topic   += '.' + self.subtopic

        self.topic        = self.topic.replace('..','.')

    def set_topic_url(self,topic_prefix,url):
        self.topic_prefix = topic_prefix
        self.topic        = topic_prefix
        self.subtopic     = ''
        relpath           = url.path

        # MG compat ?
        self.url          = url

        strpath           = relpath.strip('/')
        words             = strpath.split('/')
        if len(words) > 1 :
           self.subtopic = '.'.join(words[:-1])
           self.topic   += '.' + self.subtopic

        self.topic        = self.topic.replace('..','.')
        self.logger.debug("set_topic_url topic %s" % self.topic )
       

    def set_topic_usr(self,topic_prefix,subtopic):
        self.topic_prefix = topic_prefix
        self.subtopic     = subtopic
        self.topic        = topic_prefix + '.' + self.subtopic
        self.topic        = self.topic.replace('..','.')


    def start_timer(self):
        self.tbegin = time.time()


    # adjust headers from -headers option

    def trim_headers(self):
        self.logger.debug("trim_headers")

        for k in self.del_headers:
            if k in self.headers : del self.headers[k]

        for k in self.add_headers:
            if k in self.headers : continue
            self.headers[k] = self.add_headers[k]

    def verify_part_suffix(self,filepath):
        filename = os.path.basename(filepath)
        token    = filename.split('.')

        try :  
                 self.suffix = '.' + '.'.join(token[-6:])
                 if token[-1] != self.part_ext :
                    return False,'not right extension',None,None,None

                 self.chunksize     = int(token[-6])
                 self.block_count   = int(token[-5])
                 self.remainder     = int(token[-4])
                 self.current_block = int(token[-3])
                 self.sumflg        = token[-2]

                 if self.current_block >= self.block_count :
                    return False,'current block wrong',None,None,None
                 if self.remainder     >= self.chunksize   :
                    return False,'remainder too big',None,None,None

                 self.length    = self.chunksize
                 self.lastchunk = self.current_block == self.block_count-1
                 self.filesize  = self.block_count * self.chunksize
                 if self.remainder  > 0 :
                    self.filesize  += self.remainder - self.chunksize
                    if self.lastchunk : self.length  = self.remainder

                 lstat     = os.stat(filepath)
                 fsiz      = lstat[stat.ST_SIZE] 

                 if fsiz  != self.length :
                    return False,'wrong file size',None,None,None

                 # compute chksum
                 self.parent.set_sumalgo(self.sumflg)
                 self.sumalgo = self.parent.sumalgo

                 self.sumalgo.set_path(filepath)
                 fp = open(filepath,'rb')
                 i  = 0
                 while i<fsiz :
                       buf = fp.read(self.bufsize)
                       if not buf : break
                       self.sumalgo.update(buf)
                       i  += len(buf)
                 fp.close()

                 if i != fsiz :
                    self.logger.warning("sr_message verify_part_suffix incomplete reading %d %d" % (i,fsiz))
                    return False,'missing data from file', None,None,None

                 # set chksum
                 self.checksum  = self.sumalgo.get_value()


                 # set partstr
                 self.partstr = 'p,%d,%d,%d,%d' %\
                   (self.chunksize,self.block_count,self.remainder,self.current_block)

                 # set sumstr
                 self.sumstr  = '%s,%s' % (self.sumflg,self.checksum)

        except :
                 (stype, svalue, tb) = sys.exc_info()
                 self.logger.error("Type: %s, Value: %s" % (stype, svalue))
                 return False,'incorrect extension',None,None,None

        return True,'ok',self.suffix,self.partstr,self.sumstr


# ===================================
# checksum_0 class
# ===================================

class checksum_0(object):
      """
      Trivial minimalist checksumming algorithm, returns 0 for any file.
      """
      def __init__(self):
          self.value = '0'

      def get_value(self):
          return self.value

      def update(self,chunk):
          pass

      def set_path(self,path):
          pass

# ===================================
# checksum_d class
# ===================================

class checksum_d(object):
      """
      The default algorithm is to do a checksum of the entire contents of the file, which is called 'd'.
      """
      def __init__(self):
          self.value = '0'

      def get_value(self):
          self.value = self.filehash.hexdigest()
          return self.value

      def update(self,chunk):
          self.filehash.update(chunk)

      def set_path(self,path):
          self.filehash = md5()

# ===================================
# checksum_s class
# ===================================

class checksum_s(object):
      """
      The SHA512 algorithm to checksum the entire file, which is called 's'.
      """
      def __init__(self):
          self.value = '0'

      def get_value(self):
          self.value = self.filehash.hexdigest()
          return self.value

      def update(self,chunk):
          self.filehash.update(chunk)

      def set_path(self,path):
          self.filehash = sha512()

# ===================================
# checksum_n class
# ===================================

class checksum_n(object):
      """
      when there is more than one processing chain producing products, it can happen that files are equivalent
      without being identical, for example if each server tags a product with ''generated on server 16', then
      the generation tags will differ.   The simplest option for checksumming then is to use the name of the
      product, which is generally the same from all the processing chains.  
      """
      def __init__(self):
          self.value = '0'

      def get_value(self):
          return self.value

      def update(self,chunk):
          pass

      def set_path(self,path):
          filename   = os.path.basename(path)
          self.value = md5(bytes(filename,'utf-8')).hexdigest()

# ===================================
# startup args parsing
# ===================================

def startup_args(sys_argv):

    actions = ['foreground', 'start', 'stop', 'status', 'restart', 'reload', 'cleanup', 'declare', 'setup' ]
    actions.extend( ['add','disable', 'edit', 'enable', 'list',    'log',    'remove' ] )

    args    = None
    action  = None
    config  = None
    old     = False

    largv   = len(sys_argv)

    # work with a copy

    argv = []
    argv.extend(sys_argv)

    # program

    if largv < 2 : return (args,action,config,old)

    # program action

    if largv < 3 :
       if argv[-1] in actions : action = argv[-1]
       if argv[-1].lower().strip('-') in ['h','help'] : args = [ argv[-1] ]
       return (args,action,config,old)

    # check for action and config flags

    flagA   = False
    flagC   = False

    # program [... -[a|action] action...]

    idx = -1
    try    : idx = argv.index('-a')
    except :
             try    : idx    = argv.index('-action')
             except : pass
    if idx > -1 and idx < largv-2 :
       flagA  = True
       action = argv[idx+1]
       # strip action from args
       cmd    = ' '.join(argv)
       cmd    = cmd.replace(argv[idx] + ' ' + action, '')
       argv   = cmd.split()
       largv  = len(argv)

    # program [... -[c|config] config...]

    idx = -1
    try    : idx = argv.index('-c')
    except :
             try    : idx = argv.index('-config')
             except : pass
    if idx > -1 and idx < largv-2 :
       config = argv[idx+1]
       flagC  = True
       # strip config from args
       cmd    = ' '.join(argv)
       cmd    = cmd.replace(argv[idx] + ' ' + config, '')
       argv   = cmd.split()
       largv  = len(argv)

    # got both flags
    # program [... -[a|action] action... -[c|config] config...]
 
    if flagA and flagC :
       args = argv[1:]
       return (args,action,config,old)

    # action found... but not config
    # program [... -[a|action] action...] config

    if flagA :
       args   = argv[1:-1]
       config = argv[-1]
       return (args,action,config,old)

    # config found... but not action
    # program [... -[c|config] config...] action

    if flagC :
       args   = argv[1:-1]
       action = argv[-1]
       return (args,action,config,old)

    # positional arguments 

    # tolerate old : program [args] config action

    if argv[-1] in actions :
       action = argv[-1]
       config = argv[-2]
       args   = argv[1:-2]
       old    = True
       return (args,action,config,old)

    # program [args] action config

    action = argv[-2]
    config = argv[-1]
    args   = argv[1:-2]

    return (args,action,config,old)

def timeflt2str( f ):
    msec = '.%d' % ((f%1)*1000)
    s  = time.strftime("%Y%m%d%H%M%S",time.gmtime(f)) + msec
    return(s) 
    

def timestr2flt( s ):
    t=datetime.datetime(  int(s[0:4]), int(s[4:6]), int(s[6:8]), int(s[8:10]), int(s[10:12]), int(s[12:14]), 0, datetime.timezone.utc )
    f=calendar.timegm(  t.timetuple())+float('0'+s[14:])
    return(f)

class sr_consumer:

    def __init__(self, parent, admin=False ):
        self.logger         = parent.logger
        self.logger.debug("sr_consumer __init__")
        self.parent         = parent

        if admin : return

        self.use_pattern    = parent.masks != []
        self.accept_unmatch = parent.accept_unmatch
        self.save = False

        self.build_connection()
        self.build_consumer()
        self.build_queue()
        self.get_message()

    def build_connection(self):
        self.logger.debug("sr_consumer build_broker")

        self.broker     = self.parent.broker

        self.logger.info("AMQP  broker(%s) user(%s) vhost(%s)" % \
                        (self.broker.hostname,self.broker.username,self.broker.path) )

        self.hc = HostConnect( logger = self.logger )
        self.hc.set_pika(self.parent.use_pika)
        self.hc.set_url(self.broker)
        self.hc.connect()

    def build_consumer(self):
        self.logger.debug("sr_consumer build_consumer")

        self.consumer = Consumer(self.hc)

        if self.parent.prefetch > 0 :
            self.consumer.add_prefetch(self.parent.prefetch)

        self.consumer.build()

    def publish_back(self):
        self.logger.debug("sr_consumer publish_back")

        self.publisher = Publisher(self.hc)
        self.publisher.build()

        return self.publisher

    def get_message(self):
        self.logger.debug("sr_consumer get_message")

        if not hasattr(self.parent,'msg'):
           self.parent.msg = sr_message(self.parent)

        self.raw_msg  = None
        self.msg      = self.parent.msg
        self.msg.user = self.broker.username

    def build_queue(self):
        self.logger.debug("sr_consumer build_queue")

        self.broker      = self.parent.broker
        self.bindings    = self.parent.bindings

        self.broker_str  = self.broker.geturl().replace(':'+self.broker.password+'@','@')

        # queue name 
        self.queue_declare(build=False)

        # queue bindings 

        for tup in self.bindings :
            exchange, key = tup
            self.logger.info('Binding queue %s with key %s from exchange %s on broker %s' % \
		            ( self.queue_name, key, exchange, self.broker_str ) )
            self.msg_queue.add_binding( exchange, key )

        # queue creation 
        self.msg_queue.build()

    def close(self):
        self.hc.close()

    def consume(self):

        # acknowledge last message... we are done with it since asking for a new one
        if self.raw_msg != None : self.consumer.ack(self.raw_msg)

        # consume a new one
        self.raw_msg = self.consumer.consume(self.queue_name)
        if self.raw_msg == None : return False, self.msg

        if self.save:
           self.logger.debug("save mode active")

        # make use it as a sr_message

        try :
                 self.msg.from_amqplib(self.raw_msg)
                 self.logger.debug("notice %s " % self.msg.notice)
                 self.logger.debug("urlstr %s " % self.msg.urlstr)
        except :
                 (stype, svalue, tb) = sys.exc_info()
                 self.logger.error("Type: %s, Value: %s,  ..." % (stype, svalue))
                 self.logger.error("malformed message %s"% vars(self.raw_msg))
                 return None, None


        # make use of accept/reject
        if self.use_pattern :

           # Adjust url to account for sundew extension if present, and files do not already include the names.
           if urllib.parse.urlparse(self.msg.urlstr).path.count(":") < 1 and 'sundew_extension' in self.msg.headers.keys() :
              urlstr=self.msg.urlstr + ':' + self.msg.headers[ 'sundew_extension' ]
           else:
              urlstr=self.msg.urlstr

           self.logger.debug("sr_consumer, path being matched: %s " % ( urlstr )  ) 

           if not self.parent.isMatchingPattern(self.msg.urlstr,self.accept_unmatch) :
              self.logger.debug("Rejected by accept/reject options")
              return False,self.msg

        return True,self.msg

    def queue_declare(self,build=False):
        self.logger.debug("sr_consumer queue_declare")

        self.durable     = self.parent.durable
        self.reset       = self.parent.reset
        self.expire      = self.parent.expire
        self.message_ttl = self.parent.message_ttl

        # queue name 
        self.set_queue_name()

        # queue settings
        self.msg_queue   = Queue(self.hc,self.queue_name,durable=self.durable,reset=self.reset)

        if self.expire != None :
           self.msg_queue.add_expire(self.expire)

        if self.message_ttl != None :
           self.msg_queue.add_message_ttl(self.message_ttl)

        # queue creation if needed
        if build :
           self.logger.info("declaring queue %s on %s" % (self.queue_name,self.broker.hostname))
           self.msg_queue.build()

    def random_queue_name(self) :

        # queue file : fix it 

        queuefile  = self.parent.program_name
        if self.parent.config_name :
           queuefile += '.' + self.parent.config_name
        queuefile += '.' + self.broker.username

        # queue path

        self.queuepath = self.parent.user_cache_dir + os.sep + queuefile + '.qname'

        # ====================================================
        # FIXME get rid of this code in 2018 (after release 2.17.11a1)
        # transition old queuepath to new queuepath...

        self.old_queuepath = self.parent.user_cache_dir + os.sep + queuefile
        if os.path.isfile(self.old_queuepath) and not os.path.isfile(self.queuepath) :
           # hardlink (copy of old)
           os.link(self.old_queuepath,self.queuepath)
           # during the transition both should be available is we go back

        # get rid up to the next line
        # ====================================================

        if os.path.isfile(self.queuepath) :
           f = open(self.queuepath)
           self.queue_name = f.read()
           f.close()
           return
        
        self.queue_name  = self.queue_prefix 
        self.queue_name += '.'  + self.parent.program_name

        if self.parent.config_name : self.queue_name += '.'  + self.parent.config_name
        if self.parent.queue_suffix: self.queue_name += '.'  + self.parent.queue_suffix

        self.queue_name += '.'  + str(random.randint(0,100000000)).zfill(8)
        self.queue_name += '.'  + str(random.randint(0,100000000)).zfill(8)

        f = open(self.queuepath,'w')
        f.write(self.queue_name)
        f.close()

    def set_queue_name(self):

        self.broker       = self.parent.broker
        self.queue_prefix = 'q_'+ self.broker.username
        self.queue_name   = self.parent.queue_name

        if self.queue_name :
           if self.queue_prefix in self.queue_name : return
           self.logger.warning("non standard queue name %s" % self.queue_name )
           #self.queue_name = self.queue_prefix + '.'+ self.queue_name
           return

        self.random_queue_name()

    def cleanup(self):
        self.logger.debug("sr_consume cleanup")
        self.build_connection()
        self.set_queue_name()
        self.hc.queue_delete(self.queue_name)
        try    :
                 if hasattr(self,'queuepath') :
                    os.unlink(self.queuepath)
        except : pass

    def declare(self):
        self.logger.debug("sr_consume declare")
        self.build_connection()
        self.queue_declare(build=True)
                  
    def setup(self):
        self.logger.debug("sr_consume setup")
        self.build_connection()
        self.build_queue()

import logging
import inspect
import netifaces
import os,re,socket,sys,random
import urllib,urllib.parse
from   appdirs import *
import shutil
import sarra

try   : import amqplib.client_0_8 as amqp
except: pass

try   : import pika
except: pass

import paramiko
from   paramiko import *

class sr_config:

    def __init__(self,config=None,args=None,action=None):
        if '-V' in sys.argv :
           print("Version %s" % sarra.__version__ )
           os._exit(0)


        # package_dir     = where sarra is installed on system
        # appdirs setup... on linux it gives :
        # site_data_dir   = /usr/share/default/sarra   ** unused
        # user_data_dir   = ~/.local/share/sarra       ** unused
        #
        # site_config_dir = /etc/xdg/xdg-default/sarra
        # user_cache_dir  = ~/.cache/sarra
        # user_log_dir    = ~/.cache/sarra/var/log
        # user_config_dir = ~/.config/sarra

        self.action           = action
         
        self.appname          = 'sarra'
        self.appauthor        = 'science.gc.ca'

        self.package_dir      = os.getcwd()
        self.site_config_dir  = site_config_dir(self.appname,self.appauthor)
        self.user_config_dir  = user_config_dir(self.appname,self.appauthor)
        self.user_log_dir     = user_log_dir   (self.appname,self.appauthor)
        self.user_old_log_dir     = self.user_log_dir.replace(os.sep+'log',os.sep+'var'+os.sep+'log')
        self.user_plugins_dir = self.user_config_dir + '/plugins'
        self.http_dir         = self.user_config_dir + '/Downloads'

        # umask change for directory creation and chmod
        # 2017/06/20- FIXME commenting this out, because it seems wrong!... why override umask?
        #try    : os.umask(0)
        #except : pass

        # FIXME:
        # before 2.16.08x sr_log was a comment (that became sr_report). so the log directory was needed
        # to store configuration states.  The actual log file directory was moved under 'var/' to put
        # it out of the way.  in newer versions, the state directory for sr_report became 'reports',
        # so it is possible to have log used for the normal purpose.
        #
        # For existing configurations, if ~/.cache/sarra/var/log exists, move it to ~/.cache/sarra/log
        # so everything still works, move the old var out of the way (to var.old.)
        # and create var as a symbolic link to '.' so that var/log still works.
        # this code should be removed once all users are past the transition.
        #
        var = user_cache_dir(self.appname,self.appauthor) + "/var"
        if os.path.isdir( var ) and not os.path.islink( var ):
              print("sr_config __init__ migrating logs to new location (without 'var')")
              if os.path.isdir( self.user_log_dir ): 
                 print("sr_config __init__ moving old sr_log state directory out of the way to .old")
                 os.rename( self.user_log_dir, self.user_log_dir.replace("/log", "/log.old" ))            
              print("sr_config __init__ moving old log file directory the new location %s " % self.user_log_dir )
              shutil.move( self.user_old_log_dir, self.user_log_dir)
              print("sr_config __init__ moving old var directory out of the way to %s.old" % ( var ) )
              os.rename( var, var + ".old" )
              if sys.platform != 'win32' :
                 print("sr_config __init__ create var symlink so no scripts need to be change for now. ")
                 os.symlink( "." , var )


        try    : os.makedirs(self.user_config_dir, 0o775,True)
        except : pass
        try    : os.makedirs(self.user_plugins_dir,0o775,True)
        except : pass
        try    : os.makedirs(self.http_dir,        0o775,True)
        except : pass

        # hostname

        self.hostname  = socket.getfqdn()

        # logging is interactive at start

        self.debug     = False
        self.statehost = False
        self.hostform  = 'short'
        self.loglevel  = logging.INFO

        #self.debug    = True
        #self.loglevel = logging.DEBUG

        self.LOG_FORMAT= ('%(asctime)s [%(levelname)s] %(message)s')
        logging.basicConfig(level=self.loglevel, format = self.LOG_FORMAT )
        self.logger = logging.getLogger()
        self.logger.debug("sr_config __init__")

        # program_name

        self.program_name = re.sub(r'(-script\.pyw|\.exe|\.py)?$', '', os.path.basename(sys.argv[0]) )
        self.program_dir  = self.program_name[3:]
        self.logger.debug("sr_config program_name %s " % self.program_name)

        # config

        self.config_dir    = ''
        self.config_name   = None
        self.user_config   = config
        self.remote_config = False

        # config might be None ... in some program or if we simply instantiate a class
        # but if it is not... it better be an existing file

        if config != None :
           cdir = os.path.dirname(config)
           if cdir and cdir != '' : self.config_dir = cdir.split(os.sep)[-1]
           self.config_name = re.sub(r'(\.conf)','',os.path.basename(config))
           ok, self.user_config = self.config_path(self.program_dir,config)
           if ok :
              cdir = os.path.dirname(self.user_config)
              if cdir and cdir != '' : self.config_dir = cdir.split(os.sep)[-1]
           self.logger.debug("sr_config config_dir   %s " % self.config_dir  ) 
           self.logger.debug("sr_config config_name  %s " % self.config_name ) 
           self.logger.debug("sr_config user_config  %s " % self.user_config ) 

        # build user_cache_dir/program_name/[config_name|None] and make sure it exists

        self.user_cache_dir  = user_cache_dir (self.appname,self.appauthor)
        self.user_cache_dir += os.sep + self.program_name.replace('sr_','')
        self.user_cache_dir += os.sep + "%s" % self.config_name
        # user_cache_dir will be created later in configure()

        # keep a list of extended options

        self.extended_options = []
        self.known_options    = []


        # check arguments

        if args == [] : args = None
        self.user_args       = args

    def args(self,args):
        """

        given the command line arguments look for options, and parse them.  When they are over, 

        for use by sr_post:
        set first_arg  to be the index of the first command line argument that isn't an option.
        for sr_post the files to post are sys.argv[self.first_arg:] 

        """

        self.logger.debug("sr_config args")

        if args == None : return

        # on command line opition starts with - or --
        i = 0
        self.first_arg=0
        while i < len(args):
              n = 1
              if args[i][0] == '-' :
                 n = self.option(args[i:])
                 if n == 0 : n = 1
              elif self.first_arg == 0:
                 self.first_arg=i+1
              i = i + n

    def check(self):
        self.logger.debug("sr_config check")

    def check_extended(self):
        self.logger.debug("sr_config check_extended")

        ok = True
        for option in self.extended_options :
            if option in self.known_options : continue
            value=getattr(self,option)
            self.logger.warning("extended option %s = %s (unknown or not declared)" % (option,value) ) 
            ok = False

        return ok

    def chunksize_from_str(self,str_value):
        self.logger.debug("sr_config chunksize_from_str %s" % str_value)
        factor = 1
        if str_value[-1] in 'bB'   : str_value = str_value[:-1]
        if str_value[-1] in 'kK'   : factor = 1024
        if str_value[-1] in 'mM'   : factor = 1024 * 1024
        if str_value[-1] in 'gG'   : factor = 1024 * 1024 * 1024
        if str_value[-1] in 'tT'   : factor = 1024 * 1024 * 1024 * 1024
        if str_value[-1].isalpha() : str_value = str_value[:-1]
        chunksize = int(str_value) * factor

        return chunksize

    def config(self,path):
        self.logger.debug("sr_config config component is: %s" % self.program_name )
        self.logger.debug("sr_config %s" % path)
        self.logger.debug("action    %s" % self.action)

        if path        == None  : return
        if self.action == 'edit': return

        try:
            f = open(path, 'r')
            for line in f.readlines():
                words = line.split()
                if (len(words) >= 1 and not re.compile('^[ \t]*#').search(line)):
                    self.option(words)
            f.close()

        except:
            (stype, svalue, tb) = sys.exc_info()
            self.logger.error("Type: %s, Value: %s" % (stype, svalue))

    def config_path(self,subdir,config, mandatory=True, ctype='conf'):
        self.logger.debug("config_path = %s %s" % (subdir,config))

        if config == None : return False,None

        # priority 1 : config given is a valid path

        self.logger.debug("config_path %s " % config )
        if os.path.isfile(config) :
           return True,config

        config_file = os.path.basename(config)
        config_name = re.sub(r'(\.inc|\.conf|\.py)','',config_file)
        ext         = config_file.replace(config_name,'')
        if ext == '': ext = '.' + ctype

        # priority 1.5: config file given without extenion...
        config_path = config_name + ext
        if os.path.isfile(config_path) :
           return True,config_path

        # priority 2 : config given is a user one

        config_path = self.user_config_dir + os.sep + subdir + os.sep + config_name + ext
        self.logger.debug("config_path %s " % config_path )

        if os.path.isfile(config_path) :
           return True,config_path

        # priority 3 : config given to site config

        config_path = self.site_config_dir + os.sep + subdir + os.sep + config_name + ext
        self.logger.debug("config_path %s " % config_path )

        if os.path.isfile(config_path) :
           return True,config_path

        # priority 4 : plugins

        if subdir == 'plugins' :
           config_path = self.package_dir + os.sep + 'plugins' + os.sep + config_name + ext
           self.logger.debug("config_path %s " % config_path )
           if os.path.isfile(config_path) :
              return True,config_path

        # priority 5 : if remote_config enabled, check at given remote_config_url[]

        if self.remote_config :
           wconfig = self.wget(config)
           if wconfig != None :
              self.logger.debug("config = %s" % wconfig)
              return True, wconfig

        # return bad file ... 
        if mandatory :
          if subdir == 'plugins' :     self.logger.error("script not found %s" % config)
          elif self.action != 'edit' : self.logger.error("file not found %s" % config)
          if config == None : return False,None
          #os._exit(1)

        return False,config

    def configure(self):
        self.logger.debug("configure")
        
        # on reload : get rid of extended options... because they are lists

        self.logger.debug("clearing out extended options")
        for opt in self.extended_options :
            if hasattr(self,opt): delattr (self,opt)

        self.extended_options = []
        self.known_options    = []

        # go through normal configuration

        self.defaults()
        self.general()

        self.overwrite_defaults()

        # load/reload all config settings

        self.args   (self.user_args)
        self.config (self.user_config)

        # configure some directories if statehost was set

        self.configure_statehost()

        # verify / complete settings

        self.check()

        # check extended options

        self.check_extended()


    def configure_statehost(self):
        self.logger.debug("configure_statehost")

        hostdir = None

        # user asked for statehost

        if self.statehost :
           hostdir = self.hostname
           if self.hostform == 'short' : hostdir = self.hostname.split('.')[0] 

        # finalize user_log_dir

        if hostdir and not hostdir in self.user_log_dir :
           self.user_log_dir = self.user_log_dir[:-4] + os.sep + hostdir + '/log'

        # create user_log_dir 

        self.logger.debug("sr_config user_log_dir  %s " % self.user_log_dir ) 
        try    : os.makedirs(self.user_log_dir, 0o775,True)
        except : pass

        # finalize user_cache_dir

        if hostdir and not hostdir in self.user_cache_dir :
           self.user_cache_dir  = user_cache_dir (self.appname,self.appauthor)
           self.user_cache_dir += os.sep + hostdir
           self.user_cache_dir += os.sep + self.program_name.replace('sr_','')
           self.user_cache_dir += os.sep + "%s" % self.config_name

        # create user_cache_dir

        if not self.program_name in [ 'sr', 'sr_config' ]:
           self.logger.debug("sr_config user_cache_dir  %s " % self.user_cache_dir ) 
           try    : os.makedirs(self.user_cache_dir,  0o775,True)
           except : pass

    def declare_option(self,option):
        self.logger.debug("sr_config declare_option")
        self.known_options.append(option)

    def defaults(self):
        self.logger.debug("sr_config defaults")

        # IN BIG DEBUG
        #self.debug = True
        self.debug                = False

        self.remote_config        = False
        self.remote_config_url    = []

        self.heartbeat            = 300
        self.last_heartbeat       = time.time()

        self.loglevel             = logging.INFO
        self.logrotate            = 5
        self.report_daemons          = False

        self.bufsize              = 8192
        self.kbytes_ps            = 0

        self.sumalgo              = None
        self.lastflg              = None
        self.set_sumalgo('d')

        self.admin                = None
        self.manager              = None

        # consumer
        self.attempts             = 3   # number of times to attempt downloads.
        self.broker               = urllib.parse.urlparse('amqp://guest:guest@localhost/')
        self.bindings             = []
        self.exchange             = None
        self.exchanges            = [ 'xlog', 'xpublic', 'xreport', 'xwinnow' ]
        self.topic_prefix         = 'v02.post'
        self.subtopic             = None

        self.queue_name           = None
        self.queue_suffix         = None
        self.durable              = False
        self.expire               = 1000 *60 * 5  # 5 mins = 1000millisec * 60s * 5m 
        self.reset                = False
        self.message_ttl          = None
        self.prefetch             = 1
        self.max_queue_size       = 25000
        self.set_passwords        = True

        self.use_pattern          = False    # accept if No pattern matching
        self.accept_unmatch       = False    # accept if No pattern matching
        self.masks                = []       # All the masks (accept and reject)
        self.currentPattern       = None     # defaults to all
        self.currentDir           = os.getcwd()   # mask directory (if needed)
        self.currentFileOption    = None     # should implement metpx like stuff
        self.delete               = False

        self.report_exchange      = 'xreport'
          
        # amqp

        self.use_pika             = 'pika' in sys.modules

        # cache
        self.cache                = None
        self.caching              = False
        self.cache_stat           = False

        # save/restore
        self.save_fp              = None
        self.save_count           = 1

        # new set
        self.base_dir             = None
        self.post_base_dir        = None
        self.post_base_url        = None

        # deprecated set
        self.document_root        = None
        self.post_document_root   = None
        self.url                  = None

        self.postpath             = []
        self.movepath             = []

        #self.broker              = urllib.parse.urlparse('amqp://guest:guest@localhost/')
        #self.exchange            = None
        #self.topic_prefix        = 'v02.post'
        #self.subtopic            = None

        self.to_clusters          = None
        self.parts                = None
        self.sumflg               = 'd'

        self.rename               = None

        self.headers_to_add       = {}
        self.headers_to_del       = []

        #

        self.batch                = 100

        self.chmod                = 0o0   # Peter changed this to 0, so umask can be used. July 2017.
        self.chmod_dir            = 0o775 # added by Murray Rennie May 17, 2016
        self.chmod_log            = 0o600 
        self.cluster              = None
        self.cluster_aliases      = []

        self.destination          = None
        self.discard              = False

        self.events               = 'create|delete|link|modify'
        self.event                = 'create|delete|modify'

        self.flatten              = '/'
        self.follow_symlinks      = False
        self.force_polling        = False

        self.gateway_for          = []
        self.mirror               = False

        self.partflg              = '0'
        self.pipe                 = False
        self.post_broker          = urllib.parse.urlparse('amqp://guest:guest@localhost/')
        self.post_exchange        = None
        self.post_exchange_split  = 0
        self.preserve_mode        = True
        self.preserve_time        = True
        self.pump_flag            = False

        self.randomize            = False
        self.realpath             = False
        self.reconnect            = False
        self.reportback           = True
        self.restore              = False
        self.restore_queue        = None

        self.save                 = False
        self.save_file            = None
        self.sleep                = 0
        self.strip                = 0
        self.pstrip               = None
        self.source               = None
        self.source_from_exchange = False

        self.timeout              = None
        self.users                = {}
        self.users_flag           = False

        self.blocksize            = 0

        self.destfn_script        = None
        self.do_download          = None
        self.do_poll              = None
        self.do_send              = None

        self.inplace              = False

        self.inflight             = None

        self.notify_only          = False

        # 2 object not to reset in child
        if not hasattr(self,'logpath') :
           self.logpath           = None
        if not hasattr(self,'instance') :
           self.instance          = 0
        self.no                   = -1
        self.nbr_instances        = 1



        self.overwrite            = False
        self.recompute_chksum     = False

        self.interface            = None
        self.vip                  = None

        # Plugin defaults

        self.execfile("on_message",'msg_log')
        self.on_message_list = [ self.on_message ]
        self.execfile("on_file",'file_log')
        self.on_file_list = [ self.on_file ]
        self.execfile("on_post",'post_log')
        self.on_post_list = [ self.on_post ]

        self.execfile("on_heartbeat",'heartbeat_log')
        self.on_heartbeat_list    = [self.on_heartbeat]

        self.execfile("on_html_page",'html_page')
        self.on_html_page_list    = [self.on_html_page]

        self.on_part              = None
        self.on_part_list         = []

        self.do_task              = None
        self.do_task_list         = []

        self.on_post_list = [ self.on_post ]
        self.execfile("on_line",'line_mode')
        self.on_line_list = [ self.on_line ]

        self.on_watch             = None
        self.on_watch_list        = []

    def duration_from_str(self,str_value,setting_units='s'):
        self.logger.debug("sr_config duration_from_str %s unit %s" % (str_value,setting_units))

        # str_value should be expressed in secs 
        # unit is used to initialise the factor (ex: 's': factor = 1  'ms' : factor = 1000 )

        factor    = 1

        # most settings are in sec (or millisec)
        if setting_units[-1] == 's' :
           if setting_units == 'ms'   : factor = 1000
           if str_value[-1] in 'sS'   : factor *= 1
           if str_value[-1] in 'mM'   : factor *= 60
           if str_value[-1] in 'hH'   : factor *= 60 * 60
           if str_value[-1] in 'dD'   : factor *= 60 * 60 * 24
           if str_value[-1] in 'wW'   : factor *= 60 * 60 * 24 * 7
           if str_value[-1].isalpha() : str_value = str_value[:-1]

        elif setting_units == 'd'     :
           if str_value[-1] in 'dD'   : factor *= 1
           if str_value[-1] in 'wW'   : factor *= 7
           if str_value[-1].isalpha() : str_value = str_value[:-1]

        duration = float(str_value) * factor

        return duration


    def execfile(self, opname, path):

        setattr(self,opname,None)

        if path == 'None' or path == 'none' or path == 'off':
             self.logger.debug("Reset plugin %s to None" % opname ) 
             return

        ok,script = self.config_path('plugins',path,mandatory=True,ctype='py')
        if ok:
             self.logger.debug("installing %s plugin %s" % (opname, script ) ) 
        else:
             self.logger.error("installing %s plugin %s failed: not found " % (opname, path) ) 

        try    : 
            exec(compile(open(script).read(), script, 'exec'))
        except : 
            (stype, svalue, tb) = sys.exc_info()
            self.logger.error("Type: %s, Value: %s" % (stype, svalue))
            self.logger.error("for option %s plugin %s did not work" % (opname,path))

        if getattr(self,opname) is None:
            self.logger.error("%s plugin %s incorrect: does not set self.%s" % (opname, path, opname ))


    def heartbeat_check(self):
        now    = time.time()
        elapse = now - self.last_heartbeat
        if elapse > self.heartbeat :
           self.__on_heartbeat__()
           self.last_heartbeat = now

    def __on_heartbeat__(self):
        self.logger.debug("__on_heartbeat__")

        # invoke on_hearbeat when provided
        for plugin in self.on_heartbeat_list:
           if not plugin(self): return False

        return True



    def general(self):
        self.logger.debug("sr_config general")

        # read in provided credentials
        credent = self.user_config_dir + os.sep + 'credentials.conf'
        self.cache_url   = {}
        self.credentials = sr_credentials(self.logger)
        self.credentials.read(credent)

        defconf     = self.user_config_dir + os.sep + 'default.conf'
        self.logger.debug("defconf = %s\n" % defconf)

        if os.path.isfile(defconf) : 
           config_dir       = self.config_dir
           self.config_dir  = ''
           self.config(defconf)
           self.config_dir  = config_dir

        adminconf   = self.user_config_dir + os.sep + 'admin.conf'
        self.logger.debug("adminconf = %s\n" % adminconf)

        if os.path.isfile(adminconf) : 
           config_dir       = self.config_dir
           self.config_dir  = ''
           self.config(adminconf)
           self.config_dir  = config_dir

    def has_vip(self): 

        # no vip given... standalone always has vip.
        if self.vip == None: 
           return True

        for i in netifaces.interfaces():
            for a in netifaces.ifaddresses(i):
                if self.vip in netifaces.ifaddresses(i)[a][0].get('addr'):
                   return True
        return False
 
    def isMatchingPattern(self, chaine, accept_unmatch = False): 

        for mask in self.masks:
            self.logger.debug(mask)
            pattern, maskDir, maskFileOption, mask_regexp, accepting = mask
            if mask_regexp.match(chaine) :
               if not accepting : return False
               self.currentPattern    = pattern
               self.currentDir        = maskDir
               self.currentFileOption = maskFileOption
               self.currentRegexp     = mask_regexp
               return True

        return accept_unmatch

    def isTrue(self,S):
        s = S.lower()
        if  s == 'true' or s == 'yes' or s == 'on' or s == '1': return True
        return False

    def isNone(self,S):
        s = S.lower()
        if  s == 'false' or s == 'none' or s == 'off' or s == '0': return True
        return False

    # modified from metpx SenderFTP
    def sundew_basename_parts(self,basename):

        if self.currentPattern == None : return []
        parts = re.findall( self.currentPattern, basename )
        if len(parts) == 2 and parts[1] == '' : parts.pop(1)
        if len(parts) != 1 : return None

        lst = []
        if isinstance(parts[0],tuple) :
           lst = list(parts[0])
        else:
          lst.append(parts[0])

        return lst

    # from metpx SenderFTP
    def sundew_dirPattern(self,urlstr,basename,destDir,destName) :
        """
        does substitutions for patterns in directories.

        FIXME: destName not used?
        """
        BN = basename.split(":")
        EN = BN[0].split("_")

        BP = self.sundew_basename_parts(urlstr)

        ndestDir = ""
        DD = destDir.split("/")
        for  ddword in DD :
             if ddword == "" : continue

             nddword = ""
             DW = ddword.split("$")
             for dwword in DW :
                 nddword += self.sundew_matchPattern(BN,EN,BP,dwword,dwword)

             ndestDir += "/" + nddword 

        return ndestDir

    def sundew_getDestInfos(self, filename):
        """
        modified from sundew client

        WHATFN         -- First part (':') of filename 
        HEADFN         -- Use first 2 fields of filename
        NONE           -- Use the entire filename
        TIME or TIME:  -- TIME stamp appended
        DESTFN=fname   -- Change the filename to fname

        ex: mask[2] = 'NONE:TIME'
        """
        if self.currentFileOption == None : return filename
        timeSuffix   = ''
        satnet       = ''
        parts        = filename.split(':')
        firstPart    = parts[0]

        if 'sundew_extension' in self.msg.headers.keys() :
           parts = [ parts[0] ] + self.msg.headers[ 'sundew_extension' ].split(':')
           filename = ':'.join(parts)

        destFileName = filename

        for spec in self.currentFileOption.split(':'):
            if spec == 'WHATFN':
                destFileName =  firstPart
            elif spec == 'HEADFN':
                headParts = firstPart.split('_')
                if len(headParts) >= 2:
                    destFileName = headParts[0] + '_' + headParts[1] 
                else:
                    destFileName = headParts[0] 
            elif spec == 'SENDER' and 'SENDER=' in filename:
                 i = filename.find('SENDER=')
                 if i >= 0 : destFileName = filename[i+6:].split(':')[0]
                 if destFileName[-1] == ':' : destFileName = destFileName[:-1]
            elif spec == 'NONE':
                 if 'SENDER=' in filename:
                     i = filename.find('SENDER=')
                     destFileName = filename[:i]
                 else :
                     if len(parts) >= 6 :
                        # PX default behavior : keep 6 first fields
                        destFileName = ':'.join(parts[:6])
                        #  PDS default behavior  keep 5 first fields
                        if len(parts[4]) != 1 : destFileName = ':'.join(parts[:5])
                 # extra trailing : removed if present
                 if destFileName[-1] == ':' : destFileName = destFileName[:-1]
            elif spec == 'NONESENDER':
                 if 'SENDER=' in filename:
                     i = filename.find('SENDER=')
                     j = filename.find(':',i)
                     destFileName = filename[:i+j]
                 else :
                     if len(parts) >= 6 :
                        # PX default behavior : keep 6 first fields
                        destFileName = ':'.join(parts[:6])
                        #  PDS default behavior  keep 5 first fields
                        if len(parts[4]) != 1 : destFileName = ':'.join(parts[:5])
                 # extra trailing : removed if present
                 if destFileName[-1] == ':' : destFileName = destFileName[:-1]
            elif re.compile('SATNET=.*').match(spec):
                 satnet = ':' + spec
            elif re.compile('DESTFN=.*').match(spec):
                 destFileName = spec[7:]
            elif re.compile('DESTFNSCRIPT=.*').match(spec):
                 old_destfn_script  = self.destfn_script
                 saved_new_file    = self.new_file
                 self.new_file   = destFileName
                 self.destfn_script = None
                 script = spec[13:]
                 self.execfile('destfn_script',script)
                 if self.destfn_script != None :
                    ok = self.destfn_script(self)
                 destFileName       = self.new_file
                 self.destfn_script = old_destfn_script
                 self.new_file   = saved_new_file
                 if destFileName == None : destFileName = old_destFileName
            elif spec == 'TIME':
                if destFileName != filename :
                   timeSuffix = ':' + time.strftime("%Y%m%d%H%M%S", time.gmtime())
                   # check for PX or PDS behavior ... if file already had a time extension keep his...
                   if parts[-1][0] == '2' : timeSuffix = ':' + parts[-1]
            else:
                self.logger.error("Don't understand this DESTFN parameter: %s" % spec)
                return (None, None) 
        return destFileName + satnet + timeSuffix

    # modified from metpx SenderFTP
    def sundew_matchPattern(self,BN,EN,BP,keywd,defval) :
        if   keywd[:4] == "{T1}"    : return (EN[0])[0:1]   + keywd[4:]
        elif keywd[:4] == "{T2}"    : return (EN[0])[1:2]   + keywd[4:]
        elif keywd[:4] == "{A1}"    : return (EN[0])[2:3]   + keywd[4:]
        elif keywd[:4] == "{A2}"    : return (EN[0])[3:4]   + keywd[4:]
        elif keywd[:4] == "{ii}"    : return (EN[0])[4:6]   + keywd[4:]
        elif keywd[:6] == "{CCCC}"  : return  EN[1]         + keywd[6:]
        elif keywd[:4] == "{YY}"    : return (EN[2])[0:2]   + keywd[4:]
        elif keywd[:4] == "{GG}"    : return (EN[2])[2:4]   + keywd[4:]
        elif keywd[:4] == "{Gg}"    : return (EN[2])[4:6]   + keywd[4:]
        elif keywd[:5] == "{BBB}"   : return (EN[3])[0:3]   + keywd[5:]
        # from pds'datetime suffix... not sure
        elif keywd[:7] == "{RYYYY}" : return (BN[6])[0:4]   + keywd[7:]
        elif keywd[:5] == "{RMM}"   : return (BN[6])[4:6]   + keywd[5:]
        elif keywd[:5] == "{RDD}"   : return (BN[6])[6:8]   + keywd[5:]
        elif keywd[:5] == "{RHH}"   : return (BN[6])[8:10]  + keywd[5:]
        elif keywd[:5] == "{RMN}"   : return (BN[6])[10:12] + keywd[5:]
        elif keywd[:5] == "{RSS}"   : return (BN[6])[12:14] + keywd[5:]

        # Matching with basename parts if given

        if BP != None :
           for i,v in enumerate(BP):
               kw  = '{' + str(i) +'}'
               lkw = len(kw)
               if keywd[:lkw] == kw : return v + keywd[lkw:]

        return defval

    def option(self,words):
        self.logger.debug("sr_config option %s" % words[0])

        # option strip out '-' 

        words0 = words[0].strip('-')

        # value : variable substitutions

        words1 = None
        if len(words) > 1 :
           buser  = ''
           config = ''
           words1 = words[1]

           if self.config_name : config = self.config_name

           # options need to check if there
           if hasattr(self,'broker') and self.broker  : buser  = self.broker.username

           if '$' in words1 :
              words1 = words1.replace('${HOSTNAME}',   self.hostname)
              words1 = words1.replace('${PROGRAM}',    self.program_name)
              words1 = words1.replace('${CONFIG}',     config)
              words1 = words1.replace('${BROKER_USER}',buser)

           if '$' in words1 :
              elst = []
              plst = words1.split('}')
              for parts in plst :
                  try:
                          if '{' in parts : elst.append((parts.split('{'))[1])
                  except: pass
              for e in elst :
                  try:    words1 = words1.replace('${'+e+'}',os.environ.get(e))
                  except: pass

          
        # parsing

        needexit = False
        n        = 0
        try:
                if words0 in ['accept','get','reject']: # See: sr_config.7
                     accepting   = words0 in [ 'accept', 'get' ]
                     pattern     = words1
                     mask_regexp = re.compile(pattern)
                     n = 2

                     if len(words) > 2:
                        save_currentFileOption = self.currentFileOption
                        self.currentFileOption = words[2]
                        n = 3
                     

                     self.masks.append((pattern, self.currentDir, self.currentFileOption, mask_regexp, accepting))

                     if len(words) > 2:
                         self.currentFileOption = save_currentFileOption 

                     self.logger.debug("Masks")
                     self.logger.debug("Masks %s"% self.masks)

                elif words0 in ['accept_unmatched','accept_unmatch','au']: # See: sr_config.7
                     if (words1 is None) or words[0][0:1] == '-' : 
                        self.accept_unmatch = True
                        n = 1
                     else :
                        self.accept_unmatch = self.isTrue(words[1])
                        n = 2

                elif words0 in [ 'a', 'action' ]:
                     self.action = words1
                     n = 2

                elif words0 == 'admin': # See: sr_audit.8 
                     urlstr     = words1
                     ok, url    = self.validate_urlstr(urlstr)
                     self.admin = url
                     self.users[url.username] = 'admin'
                     if not ok or not url.scheme in ['amqp','amqps']:
                        self.logger.error("invalid admin URL (%s)" % urlstr)
                        needexit = True
                     n = 2

                elif words0 in [ 'at', 'attempts' ]: # FIXME
                     self.attempts = int(words1)
                     n = 2

                elif words0 == 'batch' : # See: sr_config.7
                     self.batch = int(words[1])
                     n = 2

                elif words0 in ['base_dir','bd']: # See: sr_config.7  for sr_post.1,sarra,sender,watch
                     path = os.path.abspath(words1)
                     if self.realpath:
                         path = os.path.realpath(path)
                     if sys.platform == 'win32':
                         self.base_dir = path.replace('\\','/')
                     else:
                         self.base_dir = path
                     # FIXME MG should we test if directory exists ? and warn if not 
                     n = 2

                elif words0 in ['broker','b'] : # See: sr_consumer.7 ++   fixme: everywhere, perhaps reduce
                     urlstr      = words1
                     ok, url     = self.validate_urlstr(urlstr)
                     self.broker = url
                     if not ok or not url.scheme in ['amqp','amqps']:
                        self.logger.error("invalid broker URL (%s)" % urlstr)
                        needexit = True
                     n = 2

                elif words0 == 'blocksize' :   # See: sr_config.7
                     self.blocksize = self.chunksize_from_str(words[1])
                     if self.blocksize == 1:
                        self.parts   =  '1'
                        ok = self.validate_parts()
                             
                     n = 2

                elif words0 == 'bufsize' :   # See: sr_config.7
                     self.bufsize = int(words[1])
                     n = 2

                elif words0 in [ 'caching', 'cache', 'no_duplicates', 'noduplicates', 'nd', 'suppress_duplicates', 'sd' ] : # See: sr_post.1 sr_watch.1
                     if (words1 is None) or words[0][0:1] == '-' : 
                        #self.caching = True
                        self.caching = 300
                        n = 1
                     else :
                        if words[1].isalpha():
                               self.caching = self.isTrue(words[1])
                               if self.caching : self.caching = 300
                        else :
                               # caching setting is in sec 
                               self.caching = int(self.duration_from_str(words1,'s'))
                               if self.caching <= 0 : self.caching = False
                        n = 2

                elif words0 == 'cache_stat'   : # FIXME! what is this?
                     if (words1 is None) or words[0][0:1] == '-' : 
                        self.cache_stat = True
                        n = 1
                     else :
                        self.cache_stat = self.isTrue(words[1])
                        n = 2


                elif words0 in [ 'chmod', 'default_mode', 'dm']:    # See: sr_config.7.rst
                     self.chmod = int(words[1],8)
                     n = 2

                elif words0 in [ 'chmod_dir', 'default_dir_mode', 'ddm' ]:    # See: sr_config.7.rst
                     self.chmod_dir = int(words[1],8)
                     n = 2

                elif words0 in [ 'chmod_log', 'default_log_mode', 'dlm' ]:    
                     self.chmod_log = int(words[1],8)
                     n = 2

                elif words0 in ['cluster','cl','from_cluster','fc']: # See: sr_config.7
                     self.cluster = words1 
                     n = 2

                elif words0 in ['cluster_aliases','ca']: # See: sr_config.7
                     self.cluster_aliases = words1.split(',')
                     n = 2

                elif words0 in ['config','c','include']: # See: sr_config.7
                     ok, include = self.config_path(self.config_dir,words1,mandatory=True,ctype='inc')
                     self.config(include)
                     n = 2

                elif words0 == 'debug': # See: sr_config.7
                     debug = self.debug
                     if (words1 is None) or words[0][0:1] == '-' : 
                        self.debug = True
                        n = 1
                     else :
                        self.debug = self.isTrue(words[1])
                        n = 2

                     if self.debug : self.loglevel = logging.DEBUG
                     else:           self.loglevel = logging.INFO

                     if debug != self.debug : self.set_loglevel()

                elif words0 == 'delete': # See: sr_sarra.8
                     if (words1 is None) or words[0][0:1] == '-' : 
                        self.delete = True
                        n = 1
                     else :
                        self.delete = self.isTrue(words[1])
                        n = 2

                elif words0 == 'destfn_script': # See: sr_sender(1)
                     self.destfn_script = None
                     self.execfile("destfn_script",words1)
                     if ( self.destfn_script == None ) and not self.isNone(words1):
                        ok = False
                     n = 2

                elif words0 == 'destination' : # See: sr_sender.1
                     urlstr           = words1
                     if words1[-1] != '/': urlstr += '/'   
                     ok, url          = self.validate_urlstr(urlstr)
                     self.destination = words1
                     if not ok :
                        self.logger.error("could not understand destination (%s)" % urlstr)
                        needexit = True
                     n = 2

                elif words0 == 'directory': # See: sr_config.7 
                     self.currentDir = words1.replace('//','/')
                     n = 2

                elif words0 in ['discard','d','download-and-discard']:  # sr_subscribe.1
                     if (words1 is None) or words[0][0:1] == '-' : 
                        self.discard = True
                        n = 1
                     else :
                        self.discard = self.isTrue(words[1])
                        n = 2

                elif words0 in ['document_root','dr']: # See sr_post.1,sarra,sender,watch
                     path = os.path.abspath(words1)
                     if self.realpath:
                         path = os.path.realpath(path)
                     if sys.platform == 'win32':
                         self.document_root = path.replace('\\','/')
                     else:
                         self.document_root = path
                     n = 2

                elif words0 == 'do_download': # See sr_config.7, sr_warra, shovel, subscribe
                     self.execfile("do_download",words1)
                     if ( self.do_download == None ) and not self.isNone(words1):
                        ok = False
                     n = 2

                elif words0 == 'do_task': # See: sr_config.1, others...
                     self.execfile("do_task",words1)
                     if ( self.do_task == None ):
                        if self.isNone(words1):
                           self.do_task_list = []
                        else:
                           ok = False
                           needexit = True
                     else:
                        self.do_task_list.append(self.do_task)
                     n = 2

                elif words0 == 'do_poll': # See sr_config.7 and sr_poll.1
                     self.execfile("do_poll",words1)
                     if ( self.do_poll == None ) and not self.isNone(words1):
                        ok = False
                     n = 2

                elif words0 == 'do_send': # See sr_config.7, and sr_sender.1
                     self.execfile("do_send",words1)
                     if ( self.do_send == None ) and not self.isNone(words1):
                        ok = False
                     n = 2

                elif words0 == 'durable'   : # See sr_config.7 ++
                     if (words1 is None) or words[0][0:1] == '-' : 
                        self.durable = True
                        n = 1
                     else :
                        self.durable = self.isTrue(words[1])
                        n = 2

                elif words0 in ['events','e']:  # See sr_watch.1
                     i = 0
                     if 'deleted' in words[1]:
                         self.logger.warning("deprecated Event spec: please change 'deleted' --> 'delete'")
                         words[1] = words[1].replace("deleted","delete")

                     if 'created' in words[1]:
                         self.logger.warning("deprecated Event spec: please change 'created' --> 'create'")
                         words[1] = words[1].replace("created","create")

                     if 'linked' in words[1]:
                         self.logger.warning("deprecated Event spec: please change 'linked' --> 'link'")
                         words[1] = words[1].replace("linked","link")

                     if 'modified' in words[1]:
                         self.logger.warning("deprecated event spec: please change 'modified' --> 'modify'")
                         words[1] = words[1].replace("modified","modify")

                     if 'create'  in words[1] : i = i + 1
                     if 'delete'  in words[1] : i = i + 1
                     if 'link' in words[1] : i = i + 1
                     if 'modify' in words[1] : i = i + 1
                     if 'move'  in words[1] : i = i + 1
                     
                     if i < len(words[1].split(',')) :
                        self.logger.error("events invalid (%s)" % words[1])
                        needexit = True

                     self.events = words[1]
                     n = 2

                elif words0 in ['exchange','ex'] : # See: sr_config.7 ++ everywhere fixme?
                     self.exchange = words1
                     n = 2

                elif words0 == 'expire' : # See: sr_config.7 ++ everywhere fixme?
                     if    words1.lower() == 'none' :
                           self.expire = None
                     else:
                           # rabbitmq setting is in millisec / user in secs
                           self.expire = int(self.duration_from_str(words1,'ms'))
                           if self.expire < 300000 : 
                              self.logger.warning("expire setting (%s) may cause problem...too low" % words[1])
                     n = 2

                elif words0 == 'filename': # See: sr_poll.1, sr_sender.1
                     self.currentFileOption = words[1]
                     n = 2

                elif words0 in [ 'flatten' ]: # See: sr_poll.1, sr_sender.1
                     self.flatten = words[1]
                     n = 2

                elif words0 in ['follow_symlinks','fs']: # See: sr_post.1, sr_watch.1
                     if (words1 is None) or words[0][0:1] == '-' : 
                        self.follow_symlinks = True
                        n = 1
                     else :
                        self.follow_symlinks = self.isTrue(words[1])
                        n = 2

                elif words0 in ['force_polling','fp']: # See: sr_post.1, sr_watch.1
                     if (words1 is None) or words[0][0:1] == '-' : 
                        self.force_polling = True
                        n = 1
                     else :
                        self.force_polling = self.isTrue(words[1])
                        n = 2

                elif words0 in ['headers']: # See: sr_config.7
                     kvlist = words1.split('=')
                     key    = kvlist[0]
                     value  = kvlist[1]

                     if value.lower() in ['none','null'] :
                        self.headers_to_del.append(key)
                     else :
                        self.headers_to_add [key] = value
                     n = 2

                elif words0 in ['gateway_for','gf']: # See: sr_config.7, sr_sarra.8, sr_sender.1 
                     self.gateway_for = words1.split(',')
                     n = 2

                elif words0 == 'heartbeat' :   # See: sr_config.7
                     # heartbeat setting is in sec 
                     self.heartbeat = self.duration_from_str(words1,'s')
                     if self.heartbeat <= 0 : self.heartbeat = 0
                     n = 2

                elif words0 in ['help','h']: # See: sr_config.7
                     self.help()
                     needexit = True
                     os._exit(0)

                elif words0 in ['hostname']: # See: dd_subscribe (obsolete option...ok)
                     self.hostname = words[1] 
                     n = 2

                elif words0 in ['inplace','in','assemble']: # See: sr_sarra.8, sr_post.1, sr_watch.1
                     if (words1 is None) or words[0][0:1] == '-' : 
                        self.inplace = True
                        n = 1
                     else :
                        self.inplace = self.isTrue(words[1])
                        n = 2

                elif words0 in ['instances','i']: # See: sr_config.7
                     self.nbr_instances = int(words[1])
                     n = 2

                elif words0 == 'interface': # See: sr_poll, sr_winnow
                     self.logger.warning("deprecated *interface* option no longer has any effect, vip is enough." )
                     self.interface = words[1]
                     n = 2

                elif words0 == 'kbytes_ps': # See: sr_sender 
                     self.kbytes_ps = int(words[1])
                     n = 2

                elif words0 in ['lock','inflight']: # See: sr_config.7, sr_subscribe.1
                     if words[1].lower() in [ 'none' ]: 
                         self.inflight=None
                     elif words[1][0].isnumeric() :
                         self.inflight = self.duration_from_str(words1,'s')
                         if self.inflight <= 1 : self.inflight = None
                     else:
                         self.inflight = words[1] 
                     n = 2

                elif words0 in ['log','l']: # See: sr_config.7 
                     self.logpath         = words1
                     if os.path.isdir(words1) :
                        self.user_log_dir = words1
                     else :
                        self.user_log_dir = os.path.dirname(words1)
                     n = 2

                elif words0 == 'pipe' : # See: FIXME
                     if (words1 is None) or words[0][0:1] == '-' : 
                        self.pipe = True
                        n = 1
                     else :
                        self.pipe = self.isTrue(words[1])
                        n = 2

                elif words0 == 'restore' : # See: sr_config.7 
                     #-- report_daemons left for transition, should be removed in 2017
                     if (words1 is None) or words[0][0:1] == '-' : 
                        self.restore = True
                        n = 1
                     else :
                        self.restore = self.isTrue(words[1])
                        n = 2

                elif words0 in ['restore_to_queue', 'restore2queue', 'r2q', 'rq']: 
                     # FIXME: should be in: sr_shovel.1
                     self.restore_queue = words1
                     n = 2

                elif words0 == 'report_daemons' or words0 == 'report_daemons': # See: sr_config.7 
                     #-- report_daemons left for transition, should be removed in 2017
                     if (words1 is None) or words[0][0:1] == '-' : 
                        self.report_daemons = True
                        n = 1
                     else :
                        self.report_daemons = self.isTrue(words[1])
                        n = 2

                elif words0 in ['report_exchange', 'lx', 'le'] : # See: sr_config.7 ++ everywhere fixme?
                     self.report_exchange = words1
                     n = 2

                elif words0 in ['logdays', 'ld', 'logrotate','lr']:  # See: sr_config.7 
                     # log setting is in days 
                     self.logrotate = int(self.duration_from_str(words1,'d'))
                     if self.logrotate < 1 : self.logrotate = 1
                     n = 2

                elif words0 in ['loglevel','ll']:  # See: sr_config.7
                     level = words1.lower()
                     if level in 'critical' : self.loglevel = logging.CRITICAL
                     if level in 'error'    : self.loglevel = logging.ERROR
                     if level in 'info'     : self.loglevel = logging.INFO
                     if level in 'warning'  : self.loglevel = logging.WARNING
                     if level in 'debug'    : self.loglevel = logging.DEBUG
                     if level in 'none'     : self.loglevel = None
                     self.set_loglevel()
                     n = 2


                elif words0 in ['manager','feeder'] : # See: sr_config.7, sr_sarra.8
                     urlstr       = words1
                     ok, url      = self.validate_urlstr(urlstr)
                     self.manager = url
                     self.users[url.username] = 'feeder'
                     if not ok or not url.scheme in ['amqp','amqps']:
                        self.logger.error("invalid manager url (%s)" % urlstr)
                        needexit = True
                     n = 2

                elif words0 == 'max_queue_size':  # See: sr_audit.8 (sr_config also)
                     self.max_queue_size = int(words[1])
                     n = 2

                elif words0 == 'message_ttl':  # See: sr_consumer.7
                     if    words1.lower() == 'none' :
                           self.message_ttl = None
                     else:
                           # rabbitmq setting is in millisec 
                           self.message_ttl = int(self.duration_from_str(words1,'ms'))
                           if self.message_ttl < 300000 :
                              self.logger.warning("message_ttl setting (%s) may cause problem...too low" % words[1])
                     n = 2

                elif words0 == 'mirror': # See: sr_config.7 
                     if (words1 is None) or words[0][0:1] == '-' : 
                        self.mirror = True
                        n = 1
                     else :
                        self.mirror = self.isTrue(words[1])
                        n = 2

                elif words0 == 'move': # See: sr_post.1
                     self.movepath = []
                     self.movepath.append(words[1])
                     self.movepath.append(words[2])
                     n = 3

                # Internal use only: when instances>1 is used, and the instances are started
                # there are N instances asked to start each one having its own number (no)
                # -no 1,  -no 2, ...  -no N
                elif words0 == 'no':
                     self.no = int(words[1])
                     n = 2

                elif words0 in ['notify_only','n','no_download']: # See: sr_subscribe.1  
                     self.logger.debug("option %s" % words[0])
                     self.notify_only = True
                     n = 1

                elif words0 == 'on_file': # See: sr_config.7, sr_sarra,shovel,subscribe
                     self.execfile("on_file",words1)
                     if ( self.on_file == None ):
                        if self.isNone(words1):
                           self.on_file_list = []
                        else:
                           ok = False
                           needexit = True
                     else:
                        self.on_file_list.append(self.on_file)

                     n = 2

                elif words0 == 'on_heartbeat': # See: sr_config.7, sr_sarra,shovel,subscribe
                     self.execfile("on_heartbeat",words1)
                     if ( self.on_heartbeat == None ):
                        if self.isNone(words1):
                           self.on_heartbeat_list = []
                        else:
                           ok = False
                           needexit = True
                     else:
                        self.on_heartbeat_list.append(self.on_heartbeat)

                     n = 2

                elif words0 == 'on_html_page': # See: sr_config
                     self.execfile("on_html_page",words1)
                     if ( self.on_html_page == None ):
                        if self.isNone(words1):
                            self.on_html_page_list = []
                        else:
                            ok = False
                            needexit = True
                     else:
                        self.on_html_page_list.append(self.on_html_page)
                     n = 2

                elif words0 == 'on_line': # See: sr_poll.1
                     self.execfile("on_line",words1)
                     if ( self.on_line == None ):
                        if self.isNone(words1):
                           self.on_line_list = []
                        else:
                           ok = False
                           needexit = True
                     else:
                        self.on_line_list.append(self.on_line)

                     n = 2

                elif ( words0 == 'on_message' ) or ( words0 == 'on_msg' ) : # See: sr_config.1, others...
                     self.execfile("on_message",words1)
                     if ( self.on_message == None ):
                        if self.isNone(words1):
                           self.on_message_list = []
                        else:
                           ok = False
                           needexit = True
                     else:
                        self.on_message_list.append(self.on_message)
                     n = 2

                elif words0 == 'on_part': # See: sr_config, sr_subscribe
                     self.execfile("on_part",words1)
                     if ( self.on_part == None ):
                        if self.isNone(words1):
                           self.on_part_list = []
                        else:
                           ok = False
                           needexit = True
                     else:
                        self.on_part_list.append(self.on_part)

                     n = 2

                elif words0 == 'on_post': # See: sr_config
                     self.execfile("on_post",words1)
                     if ( self.on_post == None ):
                        if self.isNone(words1):
                            self.on_post_list = []
                        else:
                            ok = False
                            needexit = True
                     else:
                        self.on_post_list.append(self.on_post)
                     n = 2

                elif words0 == 'on_watch': # See: sr_config
                     self.execfile("on_watch",words1)
                     if ( self.on_watch == None ):
                        if self.isNone(words1):
                            self.on_watch_list = []
                        else:
                            ok = False
                            needexit = True
                     else:
                        self.on_watch_list.append(self.on_watch)
                     n = 2

                elif words0 in ['overwrite','o'] : # See: sr_config.7
                     if (words1 is None) or words[0][0:1] == '-' : 
                        self.overwrite = True
                        n = 1
                     else :
                        self.overwrite = self.isTrue(words[1])
                        n = 2

                elif words0 == 'parts': # See: sr_poll.1, sr_watch.1
                     self.parts   = words[1]
                     ok = self.validate_parts()
                     if not ok : needexit = True
                     n = 2

                # adding paths in command line might be a mess...
                elif words0 in ['path','p']: # See: sr_post.1, sr_watch.1
                     n  = 1
                     dr = self.document_root
                     for w in words[1:]:

                         # stop if next option
                         if words[0][0:1] == '-' : 
                            if w[0:1] == '-'     : break

                         # adding path (cannot check if it exists we may post a delete)
                         try:
                                 path = w
                                 if dr and not dr in w: path = dr + os.sep + w

                                 path = os.path.abspath(path)
                                 if self.realpath:
                                     path = os.path.realpath(path)
                                 self.postpath.append(path)
                                 n = n + 1
                         except: break

                     if n == 1 :
                        self.logger.error("problem with path option")
                        needexit = True

                elif words0 in ['post_base_dir','pbd']: # See: sr_sarra,sender,shovel,winnow
                     if sys.platform == 'win32':
                         self.post_base_dir = words1.replace('\\','/')
                     else:
                         self.post_base_dir = words1
                     n = 2


                elif words0 in ['post_broker','pb'] : # See: sr_sarra,sender,shovel,winnow
                     urlstr      = words1
                     ok, url     = self.validate_urlstr(urlstr)
                     self.post_broker = url
                     if not ok or not url.scheme in ['amqp','amqps']:
                        self.logger.error("invalid post_broker url (%s)" % urlstr)
                        needexit = True
                     n = 2

                elif words0 in ['post_document_root','pdr']: # See: sr_sarra,sender,shovel,winnow
                     if sys.platform == 'win32':
                         self.post_document_root = words1.replace('\\','/')
                     else:
                         self.post_document_root = words1
                     n = 2

                elif words0 in ['post_exchange','pe','px']: # See: sr_sarra,sender,shovel,winnow 
                     self.post_exchange = words1
                     n = 2

                elif words0 in ['post_exchange_split','pes', 'pxs']: # sr_config.7, sr_shovel.1
                     self.post_exchange_split = int(words1)
                     n = 2

                elif words0 == 'prefetch': # See: sr_consumer.1  (Nbr of prefetch message when queue is shared)
                     self.prefetch = int(words1)
                     n = 2

                elif words0 in ['preserve_mode','pm'] : # See: sr_config.7
                     if (words1 is None) or words[0][0:1] == '-' : 
                        self.preserve_mode = True
                        n = 1
                     else :
                        self.preserve_mode = self.isTrue(words[1])
                        n = 2

                elif words0 in ['preserve_time','pt'] : # See: sr_config.7
                     if (words1 is None) or words[0][0:1] == '-' : 
                        self.preserve_time = True
                        n = 1
                     else :
                        self.preserve_time = self.isTrue(words[1])
                        n = 2

                elif words0 == 'pump':  # See: sr_audit.1  (give pump hints or setting errors)
                     if (words1 is None) or words[0][0:1] == '-' : 
                        self.pump_flag = True
                        n = 1
                     else :
                        self.pump_flag = self.isTrue(words[1])
                        n = 2

                elif words0 in ['queue', 'queue_name','qn'] : # See:  sr_config.7, sender, shovel, sub, winnow too much?
                     self.queue_name = words1
                     n = 2

                elif words0 in ['queue_suffix'] : # See: sr_consumer.1 : but not very usefull... could be removed
                     self.queue_suffix = words1
                     n = 2

                elif words0 in ['randomize','r']: # See: sr_watch.1, sr_post.1
                     if (words1 is None) or words[0][0:1] == '-' : 
                        self.randomize = True
                        n = 1
                     else :
                        self.randomize = self.isTrue(words[1])
                        n = 2

                elif words0 in ['realpath','real']: # See: sr_post.1, sr_watch.1
                     if (words1 is None) or words[0][0:1] == '-' : 
                        self.realpath = True
                        n = 1
                     else :
                        self.realpath = self.isTrue(words[1])
                        n = 2

                elif words0 in ['recompute_chksum','rc']: # See: sr_sarra.8
                     if (words1 is None) or words[0][0:1] == '-' : 
                        self.recompute_chksum = True
                        n = 1
                     else :
                        self.recompute_chksum = self.isTrue(words[1])
                        n = 2

                elif words0 in ['reconnect','rr']: # See: sr_post.1, sr_watch.1
                     if (words1 is None) or words[0][0:1] == '-' : 
                        self.reconnect = True
                        n = 1
                     else :
                        self.reconnect = self.isTrue(words[1])
                        n = 2

                elif words0 in ['remote_config']: # See: sr_config.7
                     if (words1 is None) or words[0][0:1] == '-' : 
                        self.remote_config = True
                        n = 1
                     else :
                        self.remote_config = self.isTrue(words[1])
                        n = 2

                elif words0 in ['remote_config_url']: # See: sr_config.7
                     self.remote_config_url.append(words[1])
                     n = 2

                elif words0 in ['rename','rn']: # See: sr_poll, sarra, sender, sub, watch? 
                     self.rename = words1
                     n = 2

                elif words0 in ['report_back','rb']:  # See: sr_subscribe.1
                     if (words1 is None) or words[0][0:1] == '-' : 
                        self.reportback = True
                        n = 1
                     else :
                        self.reportback = self.isTrue(words[1])
                        n = 2

                elif words0 in ['reset']:  # See: sr_consumer.1
                     if (words1 is None) or words[0][0:1] == '-' : 
                        self.reset = True
                        n = 1
                     else :
                        self.reset = self.isTrue(words[1])
                        n = 2

                elif words0 in [ 'role', 'declare' ]:  # See: sr_audit.1
                     item = words[1].lower()
                     if words0 in [ 'role' ]:
                        self.logger.warning("role option deprecated, please replace with 'declare'" )

                     if item in [ 'source' , 'subscriber' ]:
                        roles  = item
                        user   = words[2]
                        self.users[user] = roles
                     elif item in [ 'exchange' ]:
                        self.exchanges.append( words[2] )                                                
                     n = 3

                elif words0 == 'save' : # See: sr_config.7 
                     #-- report_daemons left for transition, should be removed in 2017
                     if (words1 is None) or words[0][0:1] == '-' : 
                        self.save = True
                        n = 1
                     else :
                        self.save = self.isTrue(words[1])
                        n = 2

                elif words0 in [ 'save_file', 'sf' ]: # FIXMEFIXME
                     self.save_file = words[1]
                     n = 2

                elif words0 in ['set_passwords']:  # See: sr_consumer.1
                     if (words1 is None) or words[0][0:1] == '-' : 
                        self.set_passwords = True
                        n = 1
                     else :
                        self.set_passwords = self.isTrue(words[1])
                        n = 2

                elif words0 == 'sleep': # See: sr_audit.8 sr_poll.1
                     # sleep setting is in sec 
                     self.sleep = self.duration_from_str(words1,'s')
                     if self.sleep <= 0 : self.sleep = 0
                     n = 2

                elif words0 == 'source': # See: sr_post.1 sr_watch.1
                     self.source = words[1]
                     n = 2

                elif words0 in ['source_from_exchange','sfe']: # See: sr_sarra.8
                     if (words1 is None ) or words[0][0:1] == '-' : 
                        self.source_from_exchange = True
                        n = 1
                     else :
                        self.source_from_exchange = self.isTrue(words[1])
                        n = 2

                elif words0 == 'statehost': # MG FIXME to be documented somewhere ???
                     self.statehost = True
                     self.hostform  = 'short'
                     if (words1 is None) or words[0][0:1] == '-' : 
                        n = 1
                     elif words1.lower() in ['short','fqdn']:
                        self.hostform  = words1.lower()
                        n = 2
                     else:
                        if not self.isTrue(words[1]): self.statehost = False
                        n = 2

                elif words0 == 'strip': # See: sr_config.7 
                     if words1.isnumeric() :
                        self.strip  = int(words1)
                        self.pstrip = None
                     else:                   
                        self.strip  = 0
                        self.pstrip = words1
                     n = 2

                elif words0 in ['subtopic','sub'] : # See: sr_config.7 
                     self.subtopic = words1
                     key = self.topic_prefix + '.' + self.subtopic
                     self.bindings.append( (self.exchange,key) )
                     self.logger.debug("BINDINGS")
                     self.logger.debug("BINDINGS %s"% self.bindings)
                     n = 2

                elif words0 == 'sum': # See: sr_config.7 
                     self.sumflg = words[1]
                     ok = self.validate_sum()
                     if not ok : needexit = True
                     n = 2

                elif words0 == 'timeout': # See: sr_sarra.8
                     # timeout setting is in sec 
                     self.timeout = int(self.duration_from_str(words1,'s'))
                     if self.timeout <= 0 : self.timeout = None
                     n = 2

                elif words0 == 'to': # See: sr_config.7
                     self.to_clusters = words1
                     n = 2

                elif words0 in ['topic_prefix','tp'] : # See: sr_config.7 
                     self.topic_prefix = words1

                elif words0 in ['post_base_url','pbu','url','u','post_url']: # See: sr_config.7 
                     if words0 in ['url','u'] : self.logger.warning("option url deprecated please use post_base_url")
                     self.url = urllib.parse.urlparse(words1)
                     self.post_base_url = words1
                     n = 2

                elif words0 == 'use_pika': # See: FIX ME
                     if (words1 is None) or words[0][0:1] == '-' :
                        self.use_pika = True
                        n = 1
                     else :
                        self.use_pika = self.isTrue(words[1])
                        n = 2

                elif words0 == 'users':  # See: sr_audit.1
                     if (words1 is None) or words[0][0:1] == '-' : 
                        self.users_flag = True
                        n = 1
                     else :
                        self.users_flag = self.isTrue(words[1])
                        n = 2

                elif words0 == 'vip': # See: sr_poll.1, sr_winnow.1
                     self.vip = words[1]
                     n = 2

                else :
                     # if unknown option is supplied, create a list for the values 
                     # FIXME: if specifying values on command line, this breaks (including all options)
                     #        dunno solution.  having it take all values allows options with > 1 word, which is very useful
                     #        see post_override plugin.
                     #
                     value = ' '.join(words[1:])
                     if not hasattr(self,words[0]):
                         self.logger.debug("unrecognized option %s %s" % (words[0],value))
                         setattr(self, words[0],[ value ])
                         self.extended_options.append(words[0])
                         self.logger.debug("extend set %s = '%s'" % (words[0],getattr(self,words[0])))
                     else:
                         value2=getattr(self,words[0])
                         value2.append(value)
                         setattr(self,words[0],value2)
                         self.logger.debug("extend add %s = '%s'" % (words[0],getattr(self,words[0])))

        except:
                (stype, svalue, tb) = sys.exc_info()
                self.logger.error("Type: %s, Value: %s,  ..." % (stype, svalue))
                self.logger.error("problem evaluating option %s" % words[0])

        if needexit :
           os._exit(1)

        return n

    def overwrite_defaults(self):
        self.logger.debug("sr_config overwrite_defaults")

    def set_sumalgo(self,sumflg):
        self.logger.debug("sr_config set_sumalgo %s" % sumflg)

        if sumflg == self.lastflg : return

        flgs = sumflg

        if len(sumflg) > 2 and sumflg[:2] in ['z,','M,']:
           flgs = sumflg[2:]

        if flgs == self.lastflg : return
        self.lastflg = flgs

        if flgs == 'd' : 
           self.sumalgo = checksum_d()
           return

        if flgs == 'n' :
           self.sumalgo = checksum_n()
           return

        if flgs in [ 's' ]:
           self.sumalgo = checksum_s()
           return

        if flgs in [ '0', 'L', 'R' ]:
           self.sumalgo = checksum_0()
           return

        sum_error    = False
        self.execfile('sumalgo',flgs)

        if self.sumalgo == None : sum_error = True

        if not sum_error and not hasattr(self.sumalgo,'set_path' ) : sum_error = True
        if not sum_error and not hasattr(self.sumalgo,'update'   ) : sum_error = True
        if not sum_error and not hasattr(self.sumalgo,'get_value') : sum_error = True

        if sum_error :
           self.logger.error("sumflg %s not working... set to 'd'" % sumflg)
           self.lastflg = 'd'
           self.sumalgo = checksum_d()


    def set_loglevel(self):

        if self.loglevel == None :
           if hasattr(self,'logger') : del self.logger
           self.logpath = None
           self.logger  = logging.RootLogger(logging.CRITICAL)
           noop         = logging.NullHandler()
           self.logger.addHandler(noop)
           return

        self.logger.setLevel(self.loglevel)

    def setlog(self):

        import logging.handlers

        self.set_loglevel()

        # no log

        if self.loglevel == None : return

        # interactive

        if self.logpath  == None :
           self.logger.debug("on screen logging")
           return

        # to file

        self.logger.debug("switching to log file %s" % self.logpath )

        del self.logger

        LOG_FORMAT   = ('%(asctime)s [%(levelname)s] %(message)s')
          
        self.handler = logging.handlers.TimedRotatingFileHandler(self.logpath, when='midnight', \
                       interval=1, backupCount=self.logrotate)
        fmt          = logging.Formatter( LOG_FORMAT )
        self.handler.setFormatter(fmt)

        self.logger = logging.RootLogger(logging.WARNING)
        self.logger.setLevel(self.loglevel)
        self.logger.addHandler(self.handler)
        os.chmod( self.logpath, self.chmod_log )


    # check url and add credentials if needed from credential file

    def validate_urlstr(self,urlstr):

        ok, details = self.credentials.get(urlstr)
        if details == None :
           self.logger.error("bad credential %s" % urlstr)
           return False, urllib.parse.urlparse(urlstr)

        return True, details.url


    def validate_parts(self):
        self.logger.debug("sr_config validate_parts %s" % self.parts)
        if not self.parts[0] in ['0','1','p','i']:
           self.logger.error("parts invalid strategy (only 0,1,p, or i)(%s)" % self.parts)
           return False

        self.partflg = self.parts[0]
        token = self.parts.split(',')

        if len(token) > 1:
           if self.partflg == '1' :
               self.logger.error("parts invalid strategy 1 (whole files) accepts no other options: (%s)" % self.parts)
               return False
           if self.partflg == 'p' : 
               self.logger.error("parts invalid strategy p arguments partial file posting not supported (%s)" % self.parts)
               return False

           if ( self.partflg == 'i' or self.partflg== '0'):
              if len(token) > 2 :
                 self.logger.error("parts invalid too much  (%s)" % self.parts)
                 return False

              try    : self.blocksize = self.chunksize_from_str(token[1])
              except :
                    self.logger.error("parts invalid blocksize given (%s)" % self.parts)
                    return False

        return True

    def validate_sum(self):
        self.logger.debug("sr_config validate_sum %s" % self.sumflg)

        sumflg = self.sumflg.split(',')[0]

        if sumflg == 'z' : sumflg = self.sumflg[2:]

        if sumflg in ['0','n','d','s','R']: return True

        try :
                 self.set_sumalgo(sumflg)
                 return True
        except : 
                 (stype, svalue, tb) = sys.exc_info()
                 self.logger.error("Type: %s, Value: %s" % (stype, svalue))
                 self.logger.error("sum invalid (%s)" % self.sumflg)
                 return False
        return False


    def wget(self,config):
        self.logger.debug("sr_config wget %s" % config)
        import urllib.request, urllib.error

        if len(self.remote_config_url) == 0 : return None

        for u in self.remote_config_url :

            url        = u + os.sep + config
            local_file = self.http_dir + os.sep + config

            try :
                req  = urllib.request.Request(url)
                resp = urllib.request.urlopen(req)
                fp   = open(local_file,'wb')
                while True:
                      chunk = resp.read(self.bufsize)
                      if not chunk : break
                      fp.write(chunk)
                fp.close()
                return local_file

            except urllib.error.HTTPError as e:
                self.logger.error('Download failed: %s', url)                    
                self.logger.error('Server couldn\'t fulfill the request. Error code: %s, %s', e.code, e.reason)
            except urllib.error.URLError as e:
                self.logger.error('Download failed: %s', url)                                    
                self.logger.error('Failed to reach server. Reason: %s', e.reason)            
            except:
                self.logger.error('Download failed: %s', url )
                self.logger.error('Uexpected error')              
                (stype, svalue, tb) = sys.exc_info()
                self.logger.error("Type: %s, Value: %s,  ..." % (stype, svalue))

        return None

import logging,os,psutil,signal,subprocess,sys
from sys import platform as _platform

class sr_instances(sr_config):

    def __init__(self,config=None,args=None,action=None):
        signal.signal(signal.SIGTERM, self.stop_signal)
        signal.signal(signal.SIGINT, self.stop_signal)
        if _platform != 'win32':
            signal.signal(signal.SIGHUP, self.reload_signal)

        sr_config.__init__(self,config,args,action)
        self.cwd = os.getcwd()
        self.configure()
        self.build_parent()

    def build_parent(self):
        self.logger.debug("sr_instances build_parent")

        self.basic_name = self.program_name
        if self.config_name : self.basic_name += '_' + self.config_name 
        self.statefile  = self.user_cache_dir + os.sep + self.basic_name + '.state'

        self.last_nbr_instances = self.file_get_int(self.statefile)
        if self.last_nbr_instances == None : self.last_nbr_instances = 0

    def build_instance(self,i):
        self.logger.debug( "sr_instances build_instance %d" % i)
        self.instance      = i
        self.instance_name = self.basic_name + '_%.4d' % i

        self.instance_str  = self.program_name
        if self.config_name: self.instance_str += ' ' + self.config_name + ' %.4d' % i

        # setting of context files

        self.pidfile       = self.user_cache_dir + os.sep + self.instance_name + '.pid'
        self.logpath       = self.user_log_dir   + os.sep + self.instance_name + '.log'
        self.save_path     = self.user_cache_dir + os.sep + self.instance_name + '.save'

        self.isrunning     = False
        self.pid           = self.file_get_int(self.pidfile)

    def exec_action(self,action,old=False):

        if old :
           self.logger.warning("Should invoke : %s [args] action config" % sys.argv[0])

        # no config file given

        if self.config_name == None:
           if   action == 'list'     : self.exec_action_on_all(action)
           elif action == 'restart'  : self.exec_action_on_all(action)
           elif action == 'reload'   : self.exec_action_on_all(action)
           elif action == 'start'    : self.exec_action_on_all(action)
           elif action == 'stop'     : self.exec_action_on_all(action)
           elif action == 'status'   : self.exec_action_on_all(action)
           else :
                self.logger.warning("Should invoke : %s [args] action config" % sys.argv[0])
           os._exit(0)

        # a config file that does not exists

        if not os.path.isfile(self.user_config) :
           if   action == 'edit'    : self.exec_action_on_config(action)
           else :
                self.logger.warning("Should invoke : %s [args] action config" % sys.argv[0])
           os._exit(0)

        # a config file exists

        if   action == 'foreground' : self.foreground_parent()
        elif action == 'reload'     : self.reload_parent()
        elif action == 'restart'    : self.restart_parent()
        elif action == 'start'      : self.start_parent()
        elif action == 'stop'       : self.stop_parent()
        elif action == 'status'     : self.status_parent()

        elif action == 'cleanup'    : self.cleanup()
        elif action == 'declare'    : self.declare()
        elif action == 'setup'      : self.setup()

        elif action == 'add'        : self.exec_action_on_config(action)
        elif action == 'disable'    : self.exec_action_on_config(action)
        elif action == 'edit'       : self.exec_action_on_config(action)
        elif action == 'enable'     : self.exec_action_on_config(action)
        elif action == 'list'       : self.exec_action_on_config(action)
        elif action == 'log'        : self.exec_action_on_config(action)
        elif action == 'remove'     : self.exec_action_on_config(action)

        else :
           self.logger.error("action unknown %s" % action)
           self.help()
           os._exit(1)

    def exec_action_on_all(self,action):

        configdir = self.user_config_dir + os.sep + self.program_dir

        if not os.path.isdir(configdir)      : return

        for confname in os.listdir(configdir):
            if action == 'list': print("%s" % confname)
            else:                subprocess.check_call([self.program_name, action, confname] )

        if action == 'list':
           print(".."+os.sep)
           print("admin.conf")
           print("credentials.conf")
           print("default.conf")


    # MG FIXME first shot
    # a lot of things should be verified
    # instead we log when something wrong
    #
    # ex.: add     : config does not end with .conf
    #      disable : program is running
    #      edit    : EDITOR variable exists
    #      enable  : .off file exists
    #      list    : add include files at the end
    #      log     : probably need to configure -n for tail
    #      remove  : program is running

    def exec_action_on_config(self,action):
        self.logger.debug("exec_action_on_config %s" % action)
        
        usr_dir = self.config_dir
        usr_fil = self.user_config

        ext     = '.conf'
        if self.user_config[-4:] == '.inc' : ext = ''

        def_dir = self.user_config_dir + os.sep + self.program_dir
        def_fil = def_dir + os.sep + self.config_name + ext

        if   action == 'add'        :
             try   : os.rename(usr_fil,def_fil)
             except: self.logger.error("cound not add %s to %s" % (self.config_name + ext,def_dir))

        elif action == 'disable'    :
             src   = def_fil.replace('.off','')
             dst   = src + '.off'
             try   : os.rename(src,dst)
             except: self.logger.error("cound not disable %s" % src )

        elif action == 'edit'       :
             if self.config_name in ['admin','default','credentials'] :
                def_fil = def_dir + os.sep + '..' + os.sep + self.config_name + ext
             try   : subprocess.check_call([ os.environ.get('EDITOR'), def_fil] )
             except: self.logger.error("problem editor %s file %s" % (os.environ.get('EDITOR'), def_fil))

        elif action == 'enable'     :
             dst   = def_fil.replace('.off','')
             src   = dst + '.off'
             try   : os.rename(src,dst)
             except: self.logger.error("cound not enable %s " % src )

        elif action == 'list'       : 
             try   : subprocess.check_call([ 'cat', usr_fil ] )
             except: self.logger.error("could not cat %s" % usr_fil )

        elif action == 'log' and ext == '.conf' :


             if self.nbr_instances == 1 :
                self.build_instance(1)
                print("\ntail -f %s\n" % self.logpath)
                try   : subprocess.check_call([ 'tail', '-f', self.logpath] )
                except: self.logger.info("stop (or error?)")
                return

             if self.no > 0 :
                self.build_instance(self.no)
                print("\ntail -f %s\n" % self.logpath)
                try   : subprocess.check_call([ 'tail', '-f', self.logpath] )
                except: self.logger.info("stop (or error?)")
                return

             no=1
             while no <= self.nbr_instances :
                   self.build_instance(no)
                   print("\ntail -f %s\n" % self.logpath)
                   if not os.path.isfile(self.logpath) : continue
                   try   : subprocess.check_call( [ 'tail', '-n10', self.logpath] )
                   except: self.logger.error("could not tail -n 10 %s" % self.logpath)
                   no = no + 1

        elif action == 'remove'     : 
             try   : os.unlink(def_fil)
             except: self.logger.error("could not remove %s" % self.logpath)

    
    def file_get_int(self,path):
        i = None
        try :
                 f = open(path,'r')
                 data = f.read()
                 f.close()
        except : return i

        try :    i = int(data)
        except : return i

        return i

    def file_set_int(self,path,i):
        try    : os.unlink(path)
        except : pass
     
        try    :
                 f = open(path,'w')
                 f.write("%d"%i)
                 f.close()
        except : pass

    def foreground_parent(self):
        self.logger.debug("sr_instances foreground_parent")
        self.nbr_instances = 0
        self.save_path     = self.user_cache_dir + os.sep + self.basic_name + '_0000.save'
        self.logpath       = None
        self.setlog()
        self.start()

    def reload_instance(self):
        if self.pid == None :
           self.logger.warning("%s was not running" % self.instance_str)
           self.start_instance()
           return

        try :
                 os.kill(self.pid, signal.SIGHUP)
                 self.logger.info("%s reload" % self.instance_str)
        except :
                 self.logger.warning("%s no reload ... strange state; restarting" % self.instance_str)
                 self.restart_instance()
    
    def reload_parent(self):

        # instance 0 is the parent... child starts at 1

        i=1
        while i <= self.nbr_instances :
              self.build_instance(i)
              self.reload_instance()
              i = i + 1

        # the number of instances has decreased... stop excedent
        while i <= self.last_nbr_instances:
              self.build_instance(i)
              self.stop_instance()
              i = i + 1

        # write nbr_instances
        self.file_set_int(self.statefile,self.nbr_instances)
    
    def reload_signal(self,sig,stack):
        self.logger.info("signal reload")
        if hasattr(self,'reload') :
           self.reload()

    def restart_instance(self):
        self.stop_instance()
        time.sleep(0.01)
        self.start_instance()

    def restart_parent(self):

        # instance 0 is the parent... child starts at 1

        i=1
        while i <= self.nbr_instances :
              self.build_instance(i)
              self.restart_instance()
              i = i + 1

        # the number of instances has decreased... stop excedent
        while i <= self.last_nbr_instances:
              self.build_instance(i)
              self.stop_instance()
              i = i + 1

        # write nbr_instances
        self.file_set_int(self.statefile,self.nbr_instances)

    def start_instance(self):

        if self.pid != None :
           try    : 
                    p = psutil.Process(self.pid)
                    self.logger.info("%s already started" % self.instance_str)
                    return
           except : 
                    self.logger.info("%s strange state... " % self.instance_str)
                    self.stop_instance()

        cmd = []
        cmd.append(sys.argv[0])
        cmd.append("--no")
        cmd.append("%d" % self.instance)
        if self.user_args   != None : cmd.extend(self.user_args)
        cmd.append("start")
        if self.user_config != None : cmd.append(self.user_config)
     
        self.logger.info("%s starting" % self.instance_str)
        self.logger.debug(" cmd = %s" % cmd)
        if self.debug :
           pid = subprocess.Popen(cmd)
        else :
           pid = subprocess.Popen(cmd,shell=False,\
                 stdin=subprocess.PIPE,stdout=subprocess.PIPE,stderr=subprocess.PIPE)

    def start_parent(self):
        self.logger.debug(" pid %d instances %d no %d \n" % (os.getpid(),self.nbr_instances,self.no))

        # as parent
        if   self.no == -1 :

             # instance 0 is the parent... child starts at 1

             i=1
             while i <= self.nbr_instances :
                   self.build_instance(i)
                   self.start_instance()
                   i = i + 1

             # the number of instances has decreased... stop excedent
             while i <= self.last_nbr_instances:
                   self.build_instance(i)
                   self.stop_instance()
                   i = i+1

             # write nbr_instances
             self.file_set_int(self.statefile,self.nbr_instances)

        # as instance
        else:
             self.logger.debug("start instance %d \n" % self.no)
             self.build_instance(self.no)
             self.pid = os.getpid()
             self.file_set_int(self.pidfile,self.pid)
             self.setlog()
             self.start()
        sys.exit(0)

    def status_instance(self):
        if self.pid == None :
           self.logger.info("%s is stopped" % self.instance_str)
           return

        try    : 
                 p = psutil.Process(self.pid)
                 status = p.status().replace('sleeping','running')
                 self.logger.info("%s is %s" % (self.instance_str,status))
                 return
        except : pass

        self.logger.info("%s no status ... strange state" % self.instance_str)

    def status_parent(self):

        # instance 0 is the parent... child starts at 1

        i=1
        while i <= self.nbr_instances :
              self.build_instance(i)
              self.status_instance()
              i = i + 1

        # the number of instances has decreased... stop excedent
        while i <= self.last_nbr_instances:
              self.build_instance(i)
              self.stop_instance()
              i = i+1

        # write nbr_instances
        self.file_set_int(self.statefile,self.nbr_instances)


    def stop_instance(self):
        if self.pid == None :
           self.logger.info("%s already stopped" % self.instance_str)
           return

        try    : 
                 self.logger.info("%s stopping" % self.instance_str)
                 os.kill(self.pid, signal.SIGTERM)
                 time.sleep(0.01)
                 os.kill(self.pid, signal.SIGKILL)

        except : pass
        try    : os.unlink(self.pidfile)
        except : pass

        self.pid = None

    def stop_parent(self):

        # instance 0 is the parent... child starts at 1

        i=1
        n = self.nbr_instances
        if n < self.last_nbr_instances :
           n = self.last_nbr_instances

        while i <= n :
              self.build_instance(i)
              self.stop_instance()
              i = i + 1

        # write nbr_instances
        self.file_set_int(self.statefile,self.nbr_instances)
    
    def stop_signal(self, sig, stack):
        self.logger.info("signal stop")
        if hasattr(self,'stop') :
           self.stop()
        os._exit(0)

import json,os,sys,time

class sr_subscribe(sr_instances):

    def __init__(self,config=None,args=None,action=None):
        sr_instances.__init__(self,config,args,action)

    def check(self):
        self.logger.debug("%s check" % self.program_name)

        # if no subtopic given... make it #  for all
        if self.bindings == []  :
           key = self.topic_prefix + '.#'
           self.bindings.append( (self.exchange,key) )
           self.logger.debug("*** BINDINGS %s"% self.bindings)

        # pattern must be used
        # if unset we will accept unmatched... so everything

        self.use_pattern          = True
        self.accept_unmatch       = self.masks == []

        # verify post_base_dir

        if self.post_base_dir == None :
           if self.post_document_root != None :
              self.post_base_dir = self.post_document_root
              self.logger.warning("use post_base_dir instead of post_document_root")
           elif self.document_root != None :
              self.post_base_dir = self.document_root
              self.logger.warning("use post_base_dir instead of document_root")

        # impacting other settings

        if self.discard:
           self.inplace    = False
           self.overwrite  = True

        # caching

        if self.caching :
           self.cache      = sr_cache(self)
           self.cache_stat = True
           self.cache.open()
           self.execfile("on_heartbeat",'heartbeat_cache')
           self.on_heartbeat_list.append(self.on_heartbeat)

        # reporting

        if self.reportback :
           self.report_exchange = 'xs_' + self.broker.username

        # do_task should have doit_download for now... make it a plugin later
        # and the download is the first thing that should be done

        if not self.doit_download in self.do_task_list :
           self.do_task_list.insert(0,self.doit_download)

    def close(self):
        self.consumer.close()

        if self.post_broker :
           if self.post_broker != self.broker : self.post_hc.close()

        if self.save_fp: self.save_fp.close()

        if hasattr(self,'ftp_link') : self.ftp_link.close()
        if hasattr(self,'http_link'): self.http_link.close()
        if hasattr(self,'sftp_link'): self.sftp_link.close()

        if self.cache :
           self.cache.save()
           self.cache.close()

    def connect(self):

        # =============
        # create message if needed
        # =============

        self.msg = sr_message(self)

        # =============
        # consumer  queue_name : let consumer takes care of it
        # =============

        self.consumer = sr_consumer(self)

        self.logger.info("reading from to %s@%s, exchange: %s" % \
                        ( self.broker.username, self.broker.hostname, self.exchange ) )

        # =============
        # report_publisher
        # =============

        if self.reportback :

           self.report_publisher     = self.consumer.publish_back()
           self.msg.report_publisher = self.report_publisher
           self.msg.report_exchange  = self.report_exchange

           self.logger.info("report_back to %s@%s, exchange: %s" % 
               ( self.broker.username, self.broker.hostname, self.msg.report_exchange ) )

        else:
           self.logger.info("report_back suppressed")


        # =============
        # in save mode...
        # =============

        if self.save :
           self.logger.warning("running in save mode")
           self.post_broker        = None
           self.consumer.save      = True
           self.consumer.save_path = self.save_path

           if self.save_file  :
              self.save_path = self.save_file + self.save_path[-10:]
              self.consumer.save_path = self.save_path

           self.save_fp       = open(self.save_path,"a")
           self.save_count    = 1
           return

        # =============
        # publisher : if self.post_broker exists
        # =============

        if self.post_broker :

           # publisher host

           self.post_hc = self.consumer.hc
           if self.post_broker != self.broker :
              self.post_hc = HostConnect( logger = self.logger )
              self.post_hc.set_pika( self.use_pika )
              self.post_hc.set_url( self.post_broker )
              self.post_hc.connect()

              self.msg.user = self.post_broker.username

           self.logger.info("Output AMQP broker(%s) user(%s) vhost(%s)" % \
                           (self.post_broker.hostname,self.post_broker.username,self.post_broker.path) )


           # publisher

           self.publisher = Publisher(self.post_hc)
           self.publisher.build()
           self.msg.publisher = self.publisher
           if self.post_exchange :
              self.msg.pub_exchange = self.post_exchange
           self.msg.post_exchange_split = self.post_exchange_split
           self.logger.info("Output AMQP exchange(%s)" % self.post_exchange )

           # amqp resources

           self.declare_exchanges()


    def __do_download__(self):

        self.logger.debug("downloading/copying %s (scheme: %s) into %s " % \
                         (self.msg.urlstr, self.msg.url.scheme, self.new_file))

        try :
                if   self.msg.url.scheme == 'http' :
                     if not hasattr(self,'http_link') :
                        self.http_link = http_transport()
                     return self.http_link.download(self)

                elif self.msg.url.scheme == 'ftp' :
                     if not hasattr(self,'ftp_link') :
                        self.ftp_link = ftp_transport()
                     return self.ftp_link.download(self)

                elif self.msg.url.scheme == 'sftp' :
                     try    : from sr_sftp       import sftp_transport
                     except : from sarra.sr_sftp import sftp_transport
                     if not hasattr(self,'sftp_link') :
                        self.sftp_link = sftp_transport()
                     return self.sftp_link.download(self)

                elif self.msg.url.scheme == 'file' :
                     return file_process(self)

                # user defined download scripts

                elif self.do_download :
                     return self.do_download(self)

        except :
                (stype, svalue, tb) = sys.exc_info()
                self.logger.error("Download  Type: %s, Value: %s,  ..." % (stype, svalue))
                if self.reportback: 
                   self.msg.report_publish(503,"Unable to process")
                self.logger.error("%s: Could not download" % self.program_name)

        if self.reportback: 
            self.msg.report_publish(503,"Service unavailable %s" % self.msg.url.scheme)

    # =============
    # __do_tasks__ (download, or send, or convert)
    # =============

    def __do_tasks__(self):
        self.logger.debug("%s __do_tasks__" % self.program_name)

        # invoke on_post when provided

        for plugin in self.do_task_list:
           if not plugin(self): return False

        return True

    # =============
    # get_source_from_exchange
    # =============

    def get_source_from_exchange(self,exchange):
        self.logger.debug("%s get_source_from_exchange %s" % (self.program_name,exchange))

        source = None
        if len(exchange) < 4 or not exchange.startswith('xs_') : return source

        # check if source is a valid declared source user

        len_u   = 0
        try:
                # look for user with role source
                for u in self.users :
                    if self.users[u] != 'source' : continue
                    if exchange[3:].startswith(u) and len(u) > len_u :
                       source = u
                       len_u  = len(u)
        except: pass

        return source

    def help(self):

        # ---------------------------
        # general startup and version
        # ---------------------------

        print("\nUsage: %s [OPTIONS] [foreground|start|stop|restart|reload|status|cleanup|setup] configfile\n" % self.program_name )
        print("version: %s \n" % sarra.__version__ )

        # ---------------------------
        # program's purpose
        # ---------------------------

        if self.program_name == 'sr_sarra' :
           print("\n%s: Subscribe to download, and Recursively Re-Announce(implements a sarracenia pump)\n"\
                    % self.program_name)
           print("\nminimal configuration includes :")
           print("broker, exchange, post_broker, [post_exchange (defaults to exchange)]\n")

        if self.program_name == 'sr_winnow' :
           print("\n%s: read messages from exchange and post them(post_exchange), suppressing duplicates\n"\
                    % self.program_name)
           print("\nminimal configuration includes :")
           print("broker, exchange, [post_broker (defaults to broker)], post_exchange\n")

        if self.program_name == 'sr_shovel' :
           print("\n%s: read messages from exchange and post them on another broker using post_exchange\n"\
                    % self.program_name)
           print("\nminimal configuration includes :")
           print("broker, exchange, post_broker, [post_exchange (defaults to exchange)]\n")

        if self.program_name == 'sr_subscribe' :
           print("\n%s: Connect to an AMQP broker, subscribe to file announcements, do timely downloads\n"\
                    % self.program_name)
           print("\nminimal configuration :")
           print("sr_subscribe start ./aaa")
           print("\t\twhere aaa is an empty file: downloads announced files on dd.weather in cwd\n")

           print("\nExamples:\n")    

           print("%s subscribe.conf start # download files and display log in stdout" % self.program_name)
           print("%s -d subscribe.conf start # discard files after downloaded and display log in stout" % self.program_name)
           print("%s -l /tmp subscribe.conf start # download files,write log file in directory /tmp" % self.program_name)
           print("%s -n subscribe.conf start # get notice only, no file downloaded and display log in stout" % self.program_name)
           print("subscribe.conf file settings, MANDATORY ones must be set for a valid configuration:")
           print("\t\t(default: amqp://anonymous:anonymous@dd.weather.gc.ca/ )")

        # ---------------------------
        # option presentations
        # ---------------------------

        print("OPTIONS:")

        # ---------------------------
        # instances
        # ---------------------------

        if self.program_name != 'sr_winnow' :
           print("\ninstances <nb_of_instances>      default 1")

        # ---------------------------
        # consumer broker
        # ---------------------------

        print("\nAMQP consumer broker settings:")
        print("\tbroker amqp{s}://<user>:<pw>@<brokerhost>[:port]/<vhost>   (MANDATORY)")

        if self.program_name == 'sr_subscribe':
           print("\t\t(default: amqp://anonymous:anonymous@dd.weather.gc.ca/ )")

        # ---------------------------
        # queue bindings
        # ---------------------------

        print("\nAMQP Queue bindings:")

        if self.program_name == 'sr_subscribe':
          print("\texchange             <name>          (default: xpublic)")
        else :
          print("\texchange             <name>          (MANDATORY)")

        print("\ttopic_prefix         <amqp pattern>  (default: v02.post)")
        print("\tsubtopic             <amqp pattern>  (default: #)")
        print("\t\t  <amqp pattern> = <directory>.<directory>.<directory>...")
        print("\t\t\t* single directory wildcard (matches one directory)")
        print("\t\t\t# wildcard (matches rest)")

        # ---------------------------
        # queue settings
        # ---------------------------

        print("\nAMQP Queue settings:")
        print("\tqueue_name    <name>         (default: program set it for you)\n")
        print("\tdurable              <boolean>       (default: False)")
        print("\texpire               <minutes>       (default: None)")
        print("\tmessage-ttl          <minutes>       (default: None)")

        # ---------------------------
        # message filtering
        # ---------------------------

        print("\nMessage targeted (filtering):")

        if self.program_name in ['sr_sarra','sr_subscribe']:
           print("\tdirectory <path>     target directory (post_base_dir/directory/\"file settings\"")
           print("\t * accept/reject following a directory option determine what is placed under it")
           print("\t\t(default currentdir/\"file settings\"")

        print("\taccept    <regexp pattern>           (default: None)")
        print("\treject    <regexp pattern>           (default: None)")
        print("\taccept_unmatch   <boolean> if no match for all accept/reject opt, accept message? (default: no).\n")
        print("\tevents    <event list>  msg events processed (default:create|delete|follow|link|modify)")
        print("\ton_message           <script>        (default None)")

        # ---------------------------
        # file download settings
        # ---------------------------

        if self.program_name in ['sr_sarra','sr_subscribe'] :
           print("\nFile download settings:")
           print("\tinplace              <boolean>       (default False)")
           print("\toverwrite            <boolean>       (default False)")
           print("\tflatten   <string>   filename= message relpath replacing '/' by *flatten*(default:'/')")
           print("\tinflight  <.string>  suffix (or prefix) on filename during downloads (default: .tmp)\n")
           print("\tmirror    <boolean>  same directory tree as message relpath or flat. (default: True)")
           print("\tstrip     <count>    nb. of directories to remove from message relpath. (default: 0)")
           print("\tbase_dir             <base_dir>      (if file is local and msg_2localfile.py is used)")
           print("\tdo_download          <script>        (default None)")
           print("\ton_file              <script>        (default None)")
           print("\n\tif the download of the url received in the amqp message needs credentials")
           print("\tyou defines the credentials in the $HOME/.config/sarra/credentials.conf")
           print("\tone url per line. as an example, the file could contain:")
           print("\thttp://myhttpuser:myhttppassword@apachehost.com/")
           print("\tftp://myftpuser:myftppassword@ftpserver.org/")
           print("\tetc...")

        # ---------------------------
        # message posting
        # ---------------------------

        print("\nAMQP posting settings:")
        print("\tpost_broker amqp{s}://<user>:<pw>@<brokerhost>[:port]/<vhost>")

        if self.program_name == 'sr_sarra' :
           print("\t\t(default: manager amqp broker in default.conf)")
           print("\tpost_exchange        <name>          (default xpublic)")
        else :
           print("\tpost_exchange        <name>          (MANDATORY)")

        print("\tpost_base_dir        <name>          (default None)")
        print("\tpost_base_url        <url>      post message: base_url         (MANDATORY)")
        print("\trecompute_chksum     <boolean>  post message: reset checksum   (default False)")
        if self.program_name == 'sr_sarra' :
           print("\tsource_from_exchange <boolean>  post message: reset headers[source] (default False)")
        print("\ton_post              <script>        (default None)")

        # ---------------------------
        # report posting
        # ---------------------------

        print("\nAMQP reporting to broker:")
        if self.program_name == 'sr_sarra':
           print("\treportback              <boolean>       (default: true)")
        else :
           print("\treportback              <boolean>       (default: false)")

        print("\treport_exchange         <name>          (default: xreport)")

        # ---------------------------
        # debugging
        # ---------------------------

        print("\nDEBUG:")
        print("\t-debug")

    # =============
    # __on_file__
    # =============

    def __on_file__(self):
        self.logger.debug("%s __on_file__" % self.program_name)

        # keep current value of these variables

        val_new_dir     = self.new_dir
        val_new_file    = self.new_file
        val_new_baseurl = self.new_baseurl
        val_new_relpath = self.new_relpath

        for plugin in self.on_file_list :

           # invoke user defined on_file when provided

           self.local_file = self.new_dir + '/' + self.new_file  # FIXME: remove in 2018, once all plugins are converted.
           self.msg.local_file = self.local_file
           saved_file = self.local_file

           self.local_dir = self.new_dir     # FIXME: remove in 2018, once all plugins are converted.
           self.msg.local_dir = self.new_dir
           saved_dir = self.new_dir

           # sender
           self.remote_file = self.new_file #FIXME: remove in 2018

           if not plugin(self): return False

           if self.msg.local_file != saved_file :
              self.logger.warning("on_file plugins 2 should replace parent.msg.local_file, by parent.new_dir and parent.new_file" )
              self.new_file = os.path.basename(self.msg.local_file)
              self.new_dir  = os.path.dirname( self.msg.local_file)

           if self.msg.local_dir != saved_dir :
              self.logger.warning("on_file plugins 2 should replace parent.msg.local_dir, by parent.new_dir" )
              self.logger.warning("parent.msg.local_dir=%s, by parent.new_dir=%s" % (self.msg.local_dir, self.new_dir) )
              self.new_dir = self.msg.local_dir

           # sender
           if self.remote_file != self.new_file : #FIXME: remove in 2018
              logger.warning("on_file plugin should be updated: replace parent.remote_file, by parent.new_file")
              self.new_file = self.remote_file

           # this code should not be removed ... necessary when the plugin changed something
           # if differences with new_dir and/or new_file...
           # reset new_relpath if it stayed the same

           if self.new_dir != val_new_dir or self.new_file != val_new_file :
              if self.new_relpath == val_new_relpath :
                 relpath = self.new_dir + '/' + self.new_file
                 if self.post_base_dir : relpath = relpath.replace(self.post_base_dir,'',1)
                 self.new_relpath = relpath
              # to do it once (per plugin changes)
              val_new_dir     = self.new_dir
              val_new_file    = self.new_file
              val_new_relpath = self.new_relpath

        return True

    # =============
    # __on_message__
    # =============

    def __on_message__(self):

        # keep current value of these variables

        val_new_dir     = self.new_dir
        val_new_file    = self.new_file
        val_new_baseurl = self.new_baseurl
        val_new_relpath = self.new_relpath

        # invoke user defined on_message when provided

        self.local_file = self.new_dir + '/' + self.new_file  # FIXME: remove in 2018, once all plugins are converted.
        self.msg.local_file = self.local_file
        saved_file = self.local_file

        self.local_dir = self.new_dir     # FIXME: remove in 2018, once all plugins are converted.
        self.msg.local_dir = self.new_dir
        saved_dir = self.new_dir

        if not hasattr(self,'new_url') :
           self.new_url = self.new_baseurl + '/' + self.new_relpath  # FIXME: remove  in 2018, new_url replaced by new_baseurl and new_relpath
           self.new_url = urllib.parse.urlparse(self.new_url)
        saved_url    = self.new_url.geturl()

        # sender
        self.remote_file = self.new_file #FIXME: remove in 2018


        for plugin in self.on_message_list :

           if not plugin(self): return False

           if self.msg.local_file != saved_file :
              self.logger.warning("on_message plugins 2 should replace parent.msg.local_file, by parent.new_dir and parent.new_file" )
              self.new_file = os.path.basename(self.local_file)
              self.new_dir  = os.path.dirname( self.local_file)

           if self.msg.local_dir != saved_dir :
              self.logger.warning("on_message plugins 2 should replace parent.msg.local_dir, by parent.new_dir" )
              self.logger.warning("parent.msg.local_dir=%s, by parent.new_dir=%s" % (self.msg.local_dir, self.new_dir) )
              self.new_dir = self.msg.local_dir

           urlstr = self.new_url.geturl()
           if urlstr != saved_url :
              self.logger.warning("on_message plugins 2 should replace self.new_url, by parent.new_baseurl and parent.new_relpath" )
              self.new_relpath = self.new_url.path
              if not self.new_baseurl in urlstr:
                 self.new_baseurl = urlstr.replace(self.new_relpath,'')
               
           # sender
           if self.remote_file != self.new_file : #FIXME: remove in 2018
              logger.warning("on_message plugin should be updated: replace parent.remote_file, by parent.new_file")
              self.new_file = self.remote_file

           # if differences with new_dir/new_file... reset new_relpath

           if self.new_dir != val_new_dir or self.new_file != val_new_file :
              if self.new_relpath == val_new_relpath :
                 relpath = self.new_dir + '/' + self.new_file
                 if self.post_base_dir : relpath = relpath.replace(self.post_base_dir,'',1)
                 self.new_relpath = relpath

        return True


    # =============
    # __on_post__ posting of message
    # =============

    def __on_post__(self):
        self.logger.debug("%s __on_post_" % self.program_name)

        self.msg.local_file = self.new_file # FIXME, remove in 2018

        # invoke on_post when provided

        for plugin in self.on_post_list:
           if not plugin(self): return False
           if ( self.msg.local_file != self.new_file ): # FIXME, remove in 2018
                self.logger.warning("on_post plugins should replace self.msg.local_file, by self.new_file" )
                self.new_file = self.msg.local_file

        ok = self.msg.publish( )

        return ok


    def overwrite_defaults(self):
        self.logger.debug("%s overwrite_defaults" % self.program_name)

        # special settings for sr_subscribe

        self.accept_unmatch = False
        self.broker         = urllib.parse.urlparse("amqp://anonymous:anonymous@dd.weather.gc.ca:5672/")
        self.exchange       = 'xpublic'
        self.inplace        = True
        self.inflight       = '.tmp'
        self.mirror         = False

        self.post_broker    = None
        self.post_exchange  = None

    # =============
    # process message  
    # =============

    def process_message(self):

        self.logger.debug("Received notice  %s %s%s" % tuple(self.msg.notice.split()[0:3]) )

        #=================================
        # complete the message (source,from_cluster,to_clusters)
        #=================================

        # if a message is received directly from a source...
        # we dont trust its settings of  source and from_cluster

        if self.source_from_exchange :
           source = self.get_source_from_exchange(self.msg.exchange)
           if source : self.msg.headers['source'] = source
           else      : del self.msg.headers['source']
           if 'from_cluster' in self.msg.headers : del self.msg.headers['from_cluster']
 
        # apply default to a message without a source
        if not 'source' in self.msg.headers :
           if self.source: self.msg.headers['source'] = self.source
           else          : self.msg.headers['source'] = self.broker.username
           self.logger.debug("message missing header, set default headers['source'] = %s" % self.msg.headers['source'])

        # apply default to a message without an origin cluster
        if not 'from_cluster' in self.msg.headers :
           if self.cluster : self.msg.headers['from_cluster'] = self.cluster
           else            : self.msg.headers['from_cluster'] = self.broker.netloc.split('@')[-1] 
           self.logger.debug("message missing header, set default headers['from_cluster'] = %s" % self.msg.headers['from_cluster'])

        # apply default to a message without routing clusters
        if not 'to_clusters' in self.msg.headers :
           if self.to_clusters  : self.msg.headers['to_clusters'] = self.to_clusters
           elif self.post_broker: self.msg.headers['to_clusters'] = self.post_broker.netloc.split('@')[-1] 
           if 'to_clusters' in self.msg.headers :
              self.logger.debug("message missing header, set default headers['to_clusters'] = %s" % self.msg.headers['to_clusters'])
           else:
              self.logger.warning("message without headers['to_clusters']")

        #=================================
        # setting up message with sr_subscribe config options
        # self.set_new    : how/where sr_subscribe is configured for that product
        # self.msg.set_new: how message settings (like parts) applies in this case
        #=================================

        self.set_new()
        self.msg.set_new()

        #=================================
        # now invoke __on_message__
        #=================================

        ok = self.__on_message__()
        if not ok : return ok

        #=================================
        # if caching is set
        #=================================

        if self.caching :
           new_msg = self.cache.check_msg(self.msg)

           if not new_msg :
              if self.reportback : self.msg.report_publish(304,'Not modified')
              self.logger.info("Ignored %s not modified" % (self.msg.notice))
              return True

        #=================================
        # if notify_only... publish if set
        #=================================

        if self.notify_only :
           if self.post_broker :
              self.logger.debug("notify_only post")
              ok = self.__on_post__()
              if ok and self.reportback : self.msg.report_publish(201,'Published')
           return True

        #=================================
        # do all tasks
        #=================================
        ok = self.__do_tasks__()

        return ok


    #=================================
    # determine a file from a relpath
    #
    # returns None,None,None     if resulting file is rejected (reject/on_message)
    # returns None,None,newrelp  if resulting file is already up to date (newname only)
    # returns dir,file,relpath   of the file determined by the message and argument relpath
    #
    #=================================

    def determine_move_file(self,name,relpath):

        # build a working message from self.msg
        w_msg = sr_message(self)
        w_msg.exchange = self.msg.exchange + ''
        w_msg.notice   = self.msg.notice   + ''
        w_msg.topic    = self.msg.topic    + ''

        w_msg.headers     = self.msg.headers.copy()
        w_msg.add_headers = self.msg.add_headers.copy()
        w_msg.del_headers = self.msg.del_headers.copy()

        # set working message  with relpath info

        w_msg.set_topic ('v02.post', relpath )
        w_msg.set_notice(self.msg.baseurl,relpath,self.msg.time)

        w_msg.parse_v02_post()

        # make use of accept/reject on working message
        if self.use_pattern :

           # Adjust url to account for sundew extension if present, and files do not already include the names.
           if urllib.parse.urlparse(w_msg.urlstr).path.count(":") < 1 and 'sundew_extension' in w_msg.headers.keys() :
              urlstr = w_msg.urlstr + ':' + w_msg.headers[ 'sundew_extension' ]
           else:
              urlstr = w_msg.urlstr

           self.logger.debug("determine_move_file, path being matched: %s " % ( urlstr )  )


           if not self.isMatchingPattern(urlstr,self.accept_unmatch) :
              self.logger.debug("Rejected by accept/reject options")
              return None,None,None

        # get a copy of received message

        saved_msg = self.msg

        # user working message to validate with on_message

        self.msg = w_msg
        self.set_new()
        self.msg.set_new()

        ok = self.__on_message__()
        if not ok : return None,None,None

        # ok what we have found

        #self.logger.debug("W new_dir     = %s" % self.new_dir)
        #self.logger.debug("W new_file    = %s" % self.new_file)
        #self.logger.debug("W new_baseurl = %s" % self.new_baseurl)
        #self.logger.debug("W new_relpath = %s" % self.new_relpath)

        # set the directory of the file we try to determine

        found = True
        try   : os.chdir(self.new_dir)
        except: found = False

        # if it is for 'newname' verify if the files are the same

        if found and name == 'newname' :
    
           if not self.overwrite and self.msg.partstr and self.msg.content_should_not_be_downloaded() :
              if self.reportback : self.msg.report_publish(304,'Not modified')
              self.new_dir  = None
              self.new_file = None

        # if it is for 'oldname' verify if the file exists

        if found and name == 'oldname' :
    
           if not os.path.exists(self.new_file):
              self.logger.debug("move: oldname not found %s" % self.new_file)
              self.new_dir  = None
              self.new_file = None

        # prepare results
        tdir  = self.new_dir
        tfile = self.new_file
        trelp = self.new_relpath

        # restore original message and settings

        self.msg = saved_msg
        self.set_new()
        self.msg.set_new()

        ok = self.__on_message__()

        try   : os.chdir(self.new_dir)
        except: pass

        # return results

        return tdir,tfile,trelp

    # =============
    # doit_download
    # =============

    def doit_download(self,parent=None):
        self.logger.debug("%s doit_download" % self.program_name)

        """
        FIXME: 201612-PAS There is perhaps several bug here:
            -- no_download is not consulted. In no_download, mkdir, deletes and links should not happen.
            -- on_file/on_part processing is not invoked for links or deletions, should it?
               do we need on_link? on_delete? ugh...
            
        """

        need_download = True

        #=================================
        # move event: case 1
        # sum has 'R,' and  self.msg.headers['newname'] provided
        # Try to move oldfile from notice to newfile from headers['newname']
        # If the move is performed or not, we continue in the module because
        # the 'R,' meaning delete old file will be performed next
        # and the move message will be (corrected and) propagated that way
        #=================================

        newname = None
        if 'newname' in self.msg.headers :
           newname = self.msg.headers

           # it means that the message notice contains info about oldpath
           oldpath = self.new_dir + '/' + self.new_file

           # we can do something if the oldpath exists
           if os.path.exists(oldpath) : 

              # determine the 'move to' file (accept/reject ok and on_message ok)
              newdir,newfile,newrelp = self.determine_move_file('newname',self.msg.headers['newname'])
              if newrelp != None : newname = newrelp

              if newfile != None :
                 newpath = newdir + '/' + newfile

                 # only if the newpath doesnt exist
                 if not os.path.exists(newpath):

                    # make sure directory exists, create it if not
                    if not os.path.isdir(newdir):
                       try   : os.makedirs(newdir,0o775,True)
                       except: pass
                       #MG FIXME : except: return False  maybe ?

                    # move
                    try   : 
                            # file link
                            if os.path.isfile(oldpath) or os.path.islink(oldpath) :
                               os.link(oldpath,newpath)
                               self.logger.info("move %s to %s (hardlink)" % (oldpath,newpath))
                            # dir rename
                            if os.path.isdir( oldpath) : 
                               os.rename(oldpath,newpath)
                               self.logger.info("move %s to %s (rename)" % (oldpath,newpath))
                            if self.reportback: self.msg.report_publish(201, 'moved')
                            need_download = False
                    except: pass
                    #MG FIXME : except: return False  maybe ?

                 # if the newpath exists log a message in debug only
                 else : 
                    self.logger.debug("could not move %s to %s (file exists)" % (oldpath,newpath))

        #=================================
        # move event: case 2
        # self.msg.headers['oldname'] provided
        # Try to move oldfile from headers['oldname'] to newfile from notice
        # If the move is performed we are done (post and) return True
        # If it doesnt work, continue and the file will be downloaded normally
        #=================================

        oldname = None
        if 'oldname' in self.msg.headers :
           oldname = self.msg.headers

           # set 'move to' file
           newpath = self.new_dir + '/' + self.new_file

           # determine oldfile infos 

           olddir,oldfile,oldrelp = self.determine_move_file('oldname',self.msg.headers['oldname'])
           if oldrelp != None : oldname = oldrelp

           if oldfile != None :
              oldpath = olddir + '/' + oldfile

              # oldfile exists: try to link it to newfile
              # if it doesnt work... pass... the newfile will be downloaded

              if os.path.exists(oldpath) : 

                 if not os.path.isdir(self.new_dir):
                    try   : os.makedirs(self.new_dir,0o775,True)
                    except: pass
                    #MG FIXME : except: return False  maybe ?

                 # move
                 ok = True
                 try   : 
                         if os.path.isfile(oldpath) or os.path.islink(oldpath) :
                            os.link(oldpath,newpath)
                            self.logger.info("move %s to %s (hardlink)" % (oldpath,newpath))
                         if os.path.isdir( oldpath) : 
                            os.rename(oldpath,newpath)
                            self.logger.info("move %s to %s (rename)" % (oldpath,newpath))
                         need_download = False
                 except: ok = False

                 if ok  :
                          need_download = False
                          if self.reportback: self.msg.report_publish(201, 'moved')

                          if self.post_broker :
                             self.msg.set_topic('v02.post',self.new_relpath)
                             self.msg.set_notice(self.new_baseurl,self.new_relpath,self.msg.time)
                             self.msg.headers['oldname'] = oldname
                             ok = self.__on_post__()
                             if ok and self.reportback : self.msg.report_publish(201,'Published')
                          return True

                 self.logger.debug("could not move %s to %s (hardlink)" % (oldpath,newpath))
                 self.logger.debug("newfile will be downloaded" % newpath)

        #=================================
        # delete event, try to delete the local product given by message
        #=================================

        if self.msg.sumflg.startswith('R') : 

           self.logger.debug("message is to remove %s" % self.new_file)

           if not 'delete' in self.events and not 'newname' in self.msg.headers : 
              self.logger.info("message to remove %s ignored (events setting)" % self.new_file)
              return True

           try : 
               path = self.new_dir + os.sep + self.new_file

               if os.path.isfile(path) : os.unlink(path)
               if os.path.islink(path) : os.unlink(path)
               if os.path.isdir (path) : os.rmdir (path)
               self.logger.debug("%s removed" % self.new_file)
               if self.reportback: self.msg.report_publish(201, 'removed')
           except:
               self.logger.error("remove %s failed." % self.new_file )
               if self.reportback: self.msg.report_publish(500, 'remove failed')

           if self.post_broker :
              self.msg.set_topic('v02.post',self.new_relpath)
              self.msg.set_notice(self.new_baseurl,self.new_relpath,self.msg.time)
              if 'newname' in self.msg.headers : self.msg.headers['newname'] = newname
              ok = self.__on_post__()
              if ok and self.reportback : self.msg.report_publish(201,'Published')

           return True

        #=================================
        # link event, try to link the local product given by message
        #=================================

        if self.msg.sumflg.startswith('L') :
           self.logger.debug("message is to link %s to %s" % ( self.new_file, self.msg.headers[ 'link' ] ) )
           if not 'link' in self.events: 
              self.logger.info("message to link %s to %s ignored (events setting)" %  \
                                            ( self.new_file, self.msg.headers[ 'link' ] ) )
              return True

           if not os.path.isdir(self.new_dir):
              try   : os.makedirs(self.new_dir,0o775,True)
              except: pass

           ok = True
           try : 
               path = self.new_dir + os.sep + self.new_file

               if os.path.isfile(path) : os.unlink(path)
               if os.path.islink(path) : os.unlink(path)
               if os.path.isdir (path) : os.rmdir (path)
               os.symlink( self.msg.headers[ 'link' ], path )
               self.logger.debug("%s linked to %s " % (self.new_file, self.msg.headers[ 'link' ]) )
               if self.reportback: self.msg.report_publish(201,'linked')
           except:
               ok = False
               self.logger.error("symlink of %s %s failed." % (self.new_file, self.msg.headers[ 'link' ]) )
               if self.reportback: self.msg.report_publish(500, 'symlink failed')

           if ok and self.post_broker :
              self.msg.set_topic('v02.post',self.new_relpath)
              self.msg.set_notice(self.new_baseurl,self.new_relpath,self.msg.time)
              ok = self.__on_post__()
              if ok and self.reportback : self.msg.report_publish(201,'Published')

           return True

        #=================================
        # prepare download 
        # the post_base_dir should exists : it the starting point of the downloads
        # make sure local directory where the file will be downloaded exists
        #=================================
        # Caveat, where the local directory has sundew substitutions, it is normal for 
        # that directory not to exist ( e.g. /home/peter/test/dd/{RYYYY} )
        # FIXME: should we remove the substitutions and check the root of the root?
        #=================================

        if self.post_base_dir and not '{' in self.post_base_dir :
           if not os.path.isdir(self.post_base_dir) :
              self.logger.error("directory %s does not exist" % self.post_base_dir)
              return False

        # pass no warning it may already exists
        try    : os.makedirs(self.new_dir,0o775,True)
        except : pass

        #=================================
        # overwrite False, user asked that if the announced file already exists,
        # verify checksum to avoid an unnecessary download
        #=================================

        if not self.overwrite and self.msg.content_should_not_be_downloaded() :
           if self.reportback: self.msg.report_publish(304, 'not modified')
           self.logger.debug("file not modified %s " % self.new_file)

           # if we are processing an entire file... we are done
           if self.msg.partflg == '1' :  return False

           need_download = False

        #=================================
        # attempt downloads
        #=================================

        if need_download :
           i  = 0
           while i < self.attempts : 
                 ok = self.__do_download__()
                 if ok : break
                 i = i + 1
           # could not download
           if not ok : return False

           # after download we dont propagate renaming... once used get rid of it
           if 'rename'  in self.msg.headers : del self.msg.headers['rename']

           # after download : setting of sum for 'z' flag ...

           if len(self.msg.sumflg) > 2 and self.msg.sumflg[:2] == 'z,':
              self.msg.set_sum(self.msg.checksum,self.msg.onfly_checksum)
              if self.reportback: self.msg.report_publish(205,'Reset Content : checksum')

           # onfly checksum is different from the message ???
           if not self.msg.onfly_checksum == self.msg.checksum :
              self.logger.warning("onfly_checksum %s differ from message %s" %
                                 (self.msg.onfly_checksum, self.msg.checksum))

              # force onfly checksum  in message

              if self.recompute_chksum :
                 #self.msg.compute_local_checksum()
                 self.msg.set_sum(self.msg.sumflg,self.msg.onfly_checksum)
                 if self.reportback: self.msg.report_publish(205,'Reset Content : checksum')


           # if the part should have been inplace... but could not

           if self.inplace and self.msg.in_partfile :
              if self.reportback: self.msg.report_publish(307,'Temporary Redirect')

           # got it : call on_part (for all parts, a file being consider
           # a 1 part product... we run on_part in all cases)

           self.msg.local_file = self.new_file # FIXME: remove in 2018
           saved_file = self.new_file

           self.msg.local_dir = self.new_dir # FIXME: remove in 2018
           saved_dir = self.new_dir

           for plugin in self.on_part_list :

              if not plugin(self): return False

              if ( self.msg.local_file != saved_file ): # FIXME: remove in 2018
                 self.logger.warning("on_part plugins 1 should replace parent.msg.local_file, by parent.new_file" )
                 self.new_file = self.msg.local_file

              if ( self.msg.local_dir != saved_dir ): # FIXME: remove in 2018
                 self.logger.warning("on_part plugins 1 should replace parent.msg.local_dir, by parent.new_dir" )
                 self.new_dir = self.msg.local_dir

           # running on_file : if it is a file, or 
           # it is a part and we are not running "inplace" (discard True)
           # or we are running in place and it is the last part.

           if self.on_file_list :
              """
                 *** FIXME ***: When reassembled, lastchunk is inserted last and therefore
                 calling on_file on lastchunk is accurate... Here, the lastchunk was inserted
                 directly into the target file... The decision of directly inserting the part
                 into the file is based on the file'size being bigger or equal to part's offset.
                 It may be the case that we were at the point of inserting the last chunk...
                 BUT IT IS POSSIBLE THAT,WHEN OVERWRITING A FILE WITH PARTS BEING SENT IN PARALLEL,
                 THE PROGRAM INSERTS THE LASTCHUNK BEFORE THE END OF COLLECTING THE FILE'PARTS...
                 HENCE AN INAPPROPRIATE CALL TO on_file ... 

                 2016/12 FIXME:  I do not understand the (not self.inplace) clause... if it is a part file
                  if it handled by on_part above, if it is the last part, it is called by reassembly below
                  do not understand why calling on this condition.

                  If think this will be called for every partition file, which I think is wrong.

              """

              if (self.msg.partflg == '1') or  \
                       (self.msg.partflg != '1' and ( \
                             (not self.inplace) or \
                             (self.inplace and (self.msg.lastchunk and not self.msg.in_partfile)))):

                 if not self.__on_file__(): return False

                 #for plugin in self.on_file_list:
                 #    if not plugin(self): return False

                 #    if ( self.msg.local_file != self.new_file ): # FIXME remove in 2018
                 #       self.logger.warning("on_file plugins should replace parent.msg.local_file, by parent.new_file" )
                 #       self.new_file = self.msg.local_file

           # discard option

           if self.discard :
              try    :
                        os.unlink(self.new_file)
                        self.logger.debug("Discarded  %s" % self.new_file)
              except :
                        (stype, svalue, tb) = sys.exc_info()
                        self.logger.error("Could not discard  Type: %s, Value: %s,  ..." % (stype, svalue))
              return False


        #=================================
        # publish our download
        #=================================

        if self.msg.partflg != '1' :
           if self.inplace : self.msg.change_partflg('i')
           else            : self.msg.change_partflg('p')

        if self.post_broker :
           self.msg.set_topic('v02.post',self.new_relpath)
           self.msg.set_notice(self.new_baseurl,self.new_relpath,self.msg.time)
           if 'oldname' in self.msg.headers : self.msg.headers['oldname'] = oldname
           ok = self.__on_post__()
           if ok and self.reportback: self.msg.report_publish(201,'Published')

        #=================================
        # if we processed a file we are done
        #=================================

        if self.msg.partflg == '1' : return True

        #=================================
        # if we processed a part (downloaded or not)
        # it can make a difference for parts that wait reassembly
        #=================================
   
        if self.inplace : file_reassemble(self)

        """
        FIXME: 2016/10 - PAS: suspect a bug: pretty sure on_file plugin should run after reassembly complete.
                         2016/12 - ok I get it: on_file is called in the inplace case above.
                                   for the parts case, it is called from reassemble correctly.
                                  
        FIXME: 2016/10 - PAS: suspect a bug: pretty sure discard should run after reassembly complete.
                    2016/12 - well maybe not, if it is discarding parts, it is probably better... hmm..
        """
        return True

    def restore_messages(self):
        self.logger.info("%s restore_messages" % self.program_name)

        # no file to restore
        if not os.path.exists(self.save_path): return

        # not active

        if self.vip  and  not self.has_vip() : return
         
        # restore_queue setup

        if self.restore_queue != None:
           user    = self.broker.username
           config  = self.config_name
           channel = self.post_hc.channel

           # create temporary exchange to publish only to restore_queue.

           self.restore_exchange = 'xs_%s.%s.%s.restore' % (user,self.program_name,config)
           self.msg.pub_exchange =  self.restore_exchange
           self.msg.post_exchange_split = 0
           channel.exchange_declare( self.restore_exchange, 'topic', auto_delete=True, durable=False)
           channel.queue_bind( self.restore_queue, self.restore_exchange, '#' )

        # display restore message count

        total = 0
        with open(self.save_path,"r") as fp :
             for json_line in fp:
                 total += 1

        self.logger.info("%s restoring %d messages from save %s " % (self.program_name,total,self.save_path) )

        # restore each message

        count = 0
        with open(self.save_path,"r") as fp :
             for json_line in fp:

                 count += 1
                 self.msg.exchange = 'save'
                 self.msg.topic, self.msg.headers, self.msg.notice = json.loads(json_line)
                 self.msg.from_amqplib()
                 self.logger.info("%s restoring message %d of %d: topic: %s" %
                                 (self.program_name,  count,total, self.msg.topic) )
                 ok = self.process_message()

        if count >= total:
           self.logger.info("%s restore complete deleting save file: %s " % ( self.program_name, self.save_path ) )
           os.unlink(self.save_path)
        else:
           self.logger.error("%s only restored %d of %d messages from save file: %s " %
                            (self.program_name, count, total, self.save_path ) )

        # only if restoring from a restore_queue : cleanup and exit

        if self.restore_queue != None:
           self.post_hc.channel.queue_unbind( self.restore_queue, self.restore_exchange, '#' )
           self.cleanup()
           os._exit(0)


    def run(self):

        self.logger.info("%s run" % self.program_name)

        # if report_daemons is false than skip 'rr_' config ... cleaning up ressources if any

        if self.config_name and self.config_name[0:3] == 'rr_'  and not self.report_daemons :
           self.logger.info("report_daemons is False, skipping %s config" % self.config_name)
           self.cleanup()
           os._exit(0)

        # reset was asked... so cleanup before connection

        if self.reset : self.cleanup()

        # loop/process messages

        self.connect()

        # restoring messages

        if self.restore or self.restore_queue :
           self.restore_messages()

        # processing messages

        while True :
              try  :
                      # if vip provided, check if has vip

                      if self.vip :
                         #  is it sleeping ?
                         if not self.has_vip() :
                            self.logger.debug("%s does not have vip=%s, is sleeping", \
                                             (self.program_name,self.vip))
                            time.sleep(5)
                            continue
                         else:
                            self.logger.debug("%s is active on vip=%s", (self.program_name,self.vip))


                      #  heartbeat
                      ok = self.heartbeat_check()

                      #  consume message
                      ok, self.msg = self.consumer.consume()
                      if not ok : continue

                      #  in save mode

                      if self.save :
                         self.save_message()
                         continue

                      #  process message (ok or not... go to the next)
                      ok = self.process_message()

              except:
                      (stype, svalue, tb) = sys.exc_info()
                      self.logger.error("Type: %s, Value: %s,  ..." % (stype, svalue))


    def save_message(self):
        self.logger.info("%s saving %d message topic: %s" % ( self.program_name,self.save_count,self.msg.topic))
        self.save_count += 1
        self.save_fp.write(json.dumps( [ self.msg.topic, self.msg.headers, self.msg.notice ], sort_keys=True ) + '\n' ) 
        self.save_fp.flush()

    def set_dir_pattern(self,cdir):

        new_dir = cdir

        if '${BD}' in cdir and self.base_dir != None :
           new_dir = new_dir.replace('${BD}',self.base_dir)

        if '${PBD}' in cdir and self.post_base_dir != None :
           new_dir = new_dir.replace('${PBD}',self.post_base_dir)

        if '${DR}' in cdir and self.document_root != None :
           self.logger.warning("DR = document_root should be replaced by BD for base_dir")
           new_dir = new_dir.replace('${DR}',self.document_root)

        if '${PDR}' in cdir and self.post_base_dir != None :
           self.logger.warning("PDR = post_document_root should be replaced by PBD for post_base_dir")
           new_dir = new_dir.replace('${PDR}',self.post_base_dir)

        if '${YYYYMMDD}' in cdir :
           YYYYMMDD = time.strftime("%Y%m%d", time.gmtime()) 
           new_dir  = new_dir.replace('${YYYYMMDD}',YYYYMMDD)

        if '${SOURCE}' in cdir :
           new_dir = new_dir.replace('${SOURCE}',self.msg.headers['source'])

        if '${HH}' in cdir :
           HH = time.strftime("%H", time.gmtime()) 
           new_dir = new_dir.replace('${HH}',HH)


        return new_dir


    # ==============================================
    # how will the download file land on this server
    # with all options, this is really tricky
    # ==============================================

    def set_new(self):

        self.logger.debug("set_new strip=%s, mirror=%s flatten=%s pbd=%s msg.relpath=%s" %  \
             ( self.strip, self.mirror, self.flatten, self.post_base_dir, self.msg.relpath ) ) 

        # relative path by default mirror 

        relpath = '%s' % self.msg.relpath

        # case S=0  sr_post -> sr_suscribe... rename in headers
        # FIXME: 255 char limit on headers, rename will break!
        if 'rename' in self.msg.headers : relpath = '%s' % self.msg.headers['rename']

        token    = relpath.split('/')
        filename = token[-1]

        # if provided, strip (integer) ... strip N heading directories
        #         or  pstrip (pattern str) strip regexp pattern from relpath
        # cannot have both (see setting of option strip in sr_config)

        if self.strip > 0 :
           strip = self.strip
           #MG folling code was a fix...
           #   if strip is a number of directories
           #   add 1 to strip not to count '/'
           #   impact to current configs avoided by commenting out

           #if relpath[0] == '/' : strip = strip + 1
           try :
                   token   = token[strip:]

           # strip too much... keep the filename
           except:
                   token   = [filename]

        # strip using a pattern

        elif self.pstrip != None :
           #MG FIXME Peter's wish to have replacement in pstrip (ex.:${SOURCE}...)
           try:    relstrip = re.sub(self.pstrip,'',relpath,1)
           except: relstrip = relpath

           # if filename dissappear... same as numeric strip, keep the filename
           if not filename in relstrip : relstrip = filename
           token = relstrip.split('/')

        # if flatten... we flatten relative path
        # strip taken into account

        if self.flatten != '/' :
           filename  = self.flatten.join(token)
           token[-1] = [filename]

        if self.currentFileOption != None :
           filename  = self.sundew_getDestInfos(filename)
           token[-1] = [filename]

        # not mirroring

        if not self.mirror :
           token = [filename]

        # uses current dir

        new_dir = ''
        if self.currentDir : new_dir = self.currentDir

        # add relpath

        if len(token) > 1 :
           new_dir = new_dir + '/' + '/'.join(token[:-1])

        if '$' in new_dir :
           new_dir = self.set_dir_pattern(new_dir)

        # resolution of sundew's dirPattern

        if 'sundew_extension' in self.msg.headers.keys() :
            tfname  = filename.split(':')[0] + ':' + self.msg.headers[ 'sundew_extension' ]
            new_dir = self.sundew_dirPattern(self.msg.urlstr,tfname,new_dir,filename)


        # reset relpath from new_dir

        relpath = new_dir + '/' + filename
        if self.post_base_dir :
           relpath = relpath.replace(self.post_base_dir, '')

        # set the results for the new file (downloading or sending)

        self.new_baseurl = 'file:'

        # final value
        # NOTE : normpath keeps '/a/b/c' and '//a/b/c' the same
        #        Everywhere else // or /../ are corrected.
        #        but if the number of / starting the path > 2  ... it will result into 1 /

        self.new_dir     = os.path.normpath(new_dir)
        self.new_file    = filename
        self.new_relpath = os.path.normpath(relpath)

        if self.post_broker and self.post_base_url :
           self.new_baseurl = self.post_base_url

        #self.logger.debug("new_dir     = %s" % self.new_dir)
        #self.logger.debug("new_file    = %s" % self.new_file)
        #self.logger.debug("new_baseurl = %s" % self.new_baseurl)
        #self.logger.debug("new_relpath = %s" % self.new_relpath)

    def reload(self):
        self.logger.info("%s reload" % self.program_name )
        self.close()
        self.configure()
        self.run()

    def start(self):
        self.logger.info("%s %s start" % (self.program_name, sarra.__version__) )
        self.run()

    def stop(self):
        self.logger.info("%s stop" % self.program_name)
        self.close()
        os._exit(0)

    def cleanup(self):
        self.logger.info("%s %s cleanup" % (self.program_name,self.config_name))

        # if report_daemons is false than skip 'rr_' config

        if self.config_name and self.config_name[0:3] == 'rr_'  and not self.report_daemons :
           self.logger.info("skipping cleanup for %s" % self.config_name)
           return

        # consumer declare

        self.consumer = sr_consumer(self,admin=True)
        self.consumer.cleanup()

        # if posting

        if self.post_broker :
           self.post_hc = self.consumer.hc
           if self.post_broker != self.broker :
              self.post_hc = HostConnect( logger = self.logger )
              self.post_hc.set_pika( self.use_pika )
              self.post_hc.set_url( self.post_broker )
              self.post_hc.connect()
           self.declare_exchanges(cleanup=True)

        # caching

        if self.caching :
           self.cache.close(unlink=True)
           self.cache = None

        self.close()

    def declare(self):
        self.logger.info("%s %s declare" % (self.program_name,self.config_name))

        # if report_daemons is false than skip 'rr_' config

        if self.config_name and self.config_name[0:3] == 'rr_'  and not self.report_daemons :
           self.logger.info("skipping declare for %s" % self.config_name)
           self.close
           return

        # consumer declare

        self.consumer = sr_consumer(self,admin=True)
        self.consumer.declare()

        # on posting host
        if self.post_broker :
           self.post_hc = self.consumer.hc
           if self.post_broker != self.broker :
              self.post_hc = HostConnect( logger = self.logger )
              self.post_hc.set_pika( self.use_pika )
              self.post_hc.set_url( self.post_broker )
              self.post_hc.connect()
           self.declare_exchanges()

        self.close()

    def declare_exchanges(self, cleanup=False):

        # restore_queue mode has no post_exchange 

        if not self.post_exchange : return

        # define post exchange (splitted ?)

        exchanges = []

        if self.post_exchange_split != 0 :
           for n in list(range(self.post_exchange_split)) :
               exchanges.append(self.post_exchange + "%02d" % n )
        else :
               exchanges.append(self.post_exchange)

        # do exchanges
              
        for x in exchanges :
            if cleanup: self.post_hc.exchange_delete(x)
            else      : self.post_hc.exchange_declare(x)


    def setup(self):
        self.logger.info("%s %s setup" % (self.program_name,self.config_name))

        # if report_daemons is false than skip 'rr_' config

        if self.config_name and self.config_name[0:3] == 'rr_'  and not self.report_daemons :
           self.logger.info("skipping setup for %s" % self.config_name)
           self.close
           return

        # consumer setup

        self.consumer = sr_consumer(self,admin=True)
        self.consumer.setup()

        # on posting host
        if self.post_broker :
           self.post_hc = self.consumer.hc
           if self.post_broker != self.broker :
              self.post_hc = HostConnect( logger = self.logger )
              self.post_hc.set_pika( self.use_pika )
              self.post_hc.set_url( self.post_broker )
              self.post_hc.connect()
           self.declare_exchanges()

        if self.caching :
           self.cache = sr_cache(self)
           self.cache.open()

        self.close()


def signal_handler(signal, frame):
    print('You pressed Ctrl+C!')
    #print('Resume in 5 seconds...')
    #time.sleep(5)
    sys.exit()
    #os.kill(os.getpid(),9)


def verify_version():
    python_version = (2,6,0)
    if sys.version_info < python_version :
        sys.stderr.write("Python version higher than 2.6.0 required.\n")
        exit(1)

    amqplib_version = '1.0.0'
    if amqp.connection.LIBRARY_PROPERTIES['library_version'] < amqplib_version:
        sys.stderr.write("Amqplib version %s or higher required.\n" % amqplib_version)
        exit(1)


                 
# =========================================
# direct invocation
# =========================================

def main():

    ldir = None
    notice_only = False
    discard = False
    config = None
    
    #get options arguments
    try:
      opts, args = getopt.getopt(sys.argv[1:],'hl:dtn',['help','log-dir=','download-and-discard','no-download'])
    except getopt.GetoptError as err:    
      print("Error 1: %s" %err)
      print("Try '%s --help' for more information." % os.path.basename(sys.argv[0]))
      sys.exit(2)                    
    
    #validate options
    if opts == [] and args == []:
      help()  
      sys.exit(1)
    for o, a in opts:
      if o in ('-h','--help'):
        help()
        sys.exit(1)
      elif o in ('-n','--no-download'):
        notice_only = True        
      elif o in ('-l','--log-dir'):
        ldir = a       
        if not os.path.exists(ldir) :
          print("Error 2: specified logging directory does not exist.")
          print("Try '%s --help' for more information."% os.path.basename(sys.argv[0]))
          sys.exit(2)
      elif o in ('-d','--download-and-discard'):
        discard = True        
        
    #validate arguments
    if len(args) == 1:
      config = args[0]
      if not os.path.exists(config) :
         print("Error 3: configuration file does not exist.")
         sys.exit(2)
    elif len(args) == 0:
      help()  
      sys.exit(1)
    else:      
      print("Error 4: too many arguments given: %s." %' '.join(args))
      print("Try '%s --help' for more information." % os.path.basename(sys.argv[0]))
      sys.exit(2)            
             

    # logging to stdout

    if ldir != None :
       fn     = config.replace(".conf","")
       lfn    = fn + "_%s" % os.getpid() + ".log"
       lfile  = ldir + os.sep + lfn

       # Standard error is redirected in the log
       sys.stderr = open(lfile, 'a')


    # instanciate consumer

    subscribe = sr_subscribe(config,None)
    subscribe.notify_only = notice_only
    subscribe.discard = discard
    
    subscribe.run()

    subscribe.close()


if __name__ == '__main__':
    verify_version()
    signal.signal(signal.SIGINT, signal_handler)
    main()
